{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuigahama/anaconda3/lib/python3.8/site-packages/torchaudio/backend/utils.py:53: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, AdamW, lr_scheduler\n",
    "from torch.distributions import Uniform\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchvision.models import resnet34, resnet50\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from libs import transform as tr\n",
    "from libs import spectrogram as spec\n",
    "from libs import criterion as cr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = False  # type: ignore\n",
    "set_seed(53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_melspec(X: np.ndarray):\n",
    "    eps = 1e-6\n",
    "    mean = X.mean()\n",
    "    X = X - mean\n",
    "    std = X.std()\n",
    "    Xstd = X / (std + eps)\n",
    "    norm_min, norm_max = Xstd.min(), Xstd.max()\n",
    "    if (norm_max - norm_min) > eps:\n",
    "        V = Xstd\n",
    "        V[V < norm_min] = norm_min\n",
    "        V[V > norm_max] = norm_max\n",
    "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        # Just zero\n",
    "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tp = pd.read_csv('../../data/train_tp.csv')\n",
    "train_fp = pd.read_csv('../../data/train_fp.csv')\n",
    "submission = pd.read_csv('../../data/sample_submission.csv')\n",
    "\n",
    "pred_target = list(submission.columns)[1:]\n",
    "\n",
    "SR = 48000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RfcxDataSet(Dataset):\n",
    "    def __init__(self,\n",
    "                 tp:pd.DataFrame,\n",
    "                 fp:pd.DataFrame,\n",
    "                 train: bool,\n",
    "                 data_path:str,\n",
    "                 pcen_parameters:dict,\n",
    "                 pre_calc=True,\n",
    "                 n_mels=128\n",
    "    ):\n",
    "        self.tp = tp\n",
    "        self.fp = fp\n",
    "        self.path = data_path\n",
    "        self.img_size = 256\n",
    "        self.train = train\n",
    "        self.n_mels = n_mels\n",
    "        self.pre_calc = pre_calc\n",
    "        \n",
    "        self.pcen_parameters = pcen_parameters\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tp)\n",
    "    \n",
    "    def load(self, record_path):\n",
    "        y, orig_sr = sf.read(record_path)\n",
    "        \n",
    "        if orig_sr != SR:\n",
    "            y = librosa.resample(y, orig_sr=orig_sr, target_sr=SR, res_type=\"kaiser_best\")\n",
    "        return y\n",
    "    \n",
    "    def get_duration(self, t_min, t_max, duration=10):\n",
    "        annotated_duration = t_max - t_min\n",
    "        \n",
    "        if annotated_duration > duration:\n",
    "            limit_sec = t_max - duration\n",
    "            start_sec = random.randint(t_min, limit_sec)\n",
    "            end_sec = start_sec + duration\n",
    "\n",
    "        else:\n",
    "            res_time = duration - annotated_duration\n",
    "            front_limit = res_time if res_time < t_min else t_min\n",
    "            \n",
    "            front_time = random.randint(0, front_limit)\n",
    "            \n",
    "            back_limit = 60 - t_max\n",
    "            \n",
    "            tmp_time = res_time - front_time\n",
    "            back_time = tmp_time if tmp_time < back_limit else back_limit\n",
    "            \n",
    "            if not tmp_time < back_limit:\n",
    "                front_time += tmp_time - back_limit\n",
    "            \n",
    "            start_sec = t_min - front_time\n",
    "            end_sec = t_max + back_time\n",
    "            \n",
    "        return start_sec, end_sec\n",
    "    \n",
    "    def create_mel(self, y, target_fp):\n",
    "        melspec = librosa.feature.melspectrogram(\n",
    "            y,\n",
    "            sr=SR,\n",
    "            fmin=0,\n",
    "            fmax=15000,\n",
    "            n_mels=128\n",
    "        )\n",
    "\n",
    "        f, m = melspec.shape\n",
    "        time_rate = m / 60\n",
    "        freq_rate = f / 15000\n",
    "\n",
    "        for i in range(len(target_fp)):\n",
    "            sample = target_fp.iloc[i]\n",
    "            f_min = int(sample['f_min'] * freq_rate)\n",
    "            f_max = int(sample['f_max'] * freq_rate)\n",
    "\n",
    "            melspec[f_min:f_max, :] = 1e-4\n",
    "\n",
    "        pcen = librosa.pcen(melspec, sr=SR, **self.pcen_parameters)\n",
    "        clean_mel = librosa.power_to_db(melspec ** 1.5)\n",
    "        melspec = librosa.power_to_db(melspec)\n",
    "\n",
    "        norm_melspec = normalize_melspec(melspec)\n",
    "        norm_pcen = normalize_melspec(pcen)\n",
    "        norm_clean_mel = normalize_melspec(clean_mel)\n",
    "\n",
    "        image = np.stack([norm_melspec, norm_pcen, norm_clean_mel], axis=-1)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        sample = self.tp.iloc[idx, :]\n",
    "        recording_id = sample['recording_id']\n",
    "        t_min = int(round(sample['t_min']))\n",
    "        t_max = int(round(sample['t_max']))\n",
    "        \n",
    "        target_fp = self.fp.query(f'recording_id == \"{recording_id}\"')\n",
    "        \n",
    "        if self.pre_calc:\n",
    "            image = torch.load(self.path + recording_id + '.tensor')\n",
    "        else:\n",
    "            record_path = self.path + recording_id + '.flac'\n",
    "            y = self.load(record_path)\n",
    "            image = self.create_mel(y, target_fp)\n",
    "        \n",
    "        time_rate = int(image.shape[1] / 60)\n",
    "        \n",
    "        start_sec, end_sec = self.get_duration(t_min, t_max)\n",
    "        \n",
    "        start = int(start_sec * time_rate)\n",
    "        end = int(end_sec * time_rate)\n",
    "        \n",
    "        image = image[:, start:end, :]\n",
    "        \n",
    "        height, width, _ = image.shape\n",
    "        image = cv2.resize(image, (self.img_size * 2, self.img_size))\n",
    "        image = np.moveaxis(image, 2, 0)\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "        \n",
    "        species_id = sample['species_id']\n",
    "        target = torch.zeros([24], dtype=torch.float32)\n",
    "        target[species_id] = 1\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RfcxVal(Dataset):\n",
    "    def __init__(self,\n",
    "                 tp:pd.DataFrame,\n",
    "                 train: bool,\n",
    "                 data_path:str,\n",
    "                 pcen_parameters:dict,\n",
    "                 pre_calc=True,\n",
    "                 n_mels=128\n",
    "    ):\n",
    "        self.tp = tp\n",
    "        self.path = data_path\n",
    "        self.img_size = 256\n",
    "        self.train = train\n",
    "        self.n_mels = n_mels\n",
    "        self.pre_calc = pre_calc\n",
    "        \n",
    "        self.pcen_parameters = pcen_parameters\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tp)\n",
    "    \n",
    "    def load(self, record_path):\n",
    "        y, orig_sr = sf.read(record_path)\n",
    "        \n",
    "        if orig_sr != SR:\n",
    "            y = librosa.resample(y, orig_sr=orig_sr, target_sr=SR, res_type=\"kaiser_best\")\n",
    "        return y\n",
    "    \n",
    "    def create_mel(self, y):\n",
    "        melspec = librosa.feature.melspectrogram(\n",
    "            y,\n",
    "            sr=SR,\n",
    "            fmin=0,\n",
    "            fmax=15000,\n",
    "            n_mels=128\n",
    "        )\n",
    "        pcen = librosa.pcen(melspec, sr=SR, **self.pcen_parameters)\n",
    "        clean_mel = librosa.power_to_db(melspec ** 1.5)\n",
    "        melspec = librosa.power_to_db(melspec)\n",
    "\n",
    "        norm_melspec = normalize_melspec(melspec)\n",
    "        norm_pcen = normalize_melspec(pcen)\n",
    "        norm_clean_mel = normalize_melspec(clean_mel)\n",
    "\n",
    "        image = np.stack([norm_melspec, norm_pcen, norm_clean_mel], axis=-1)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        sample = self.tp.iloc[idx, :]\n",
    "        recording_id = sample['recording_id']\n",
    "        \n",
    "        if self.pre_calc:\n",
    "            image_ = torch.load(self.path + recording_id + '.tensor')\n",
    "        else:\n",
    "            record_path = self.path + recording_id + '.flac'\n",
    "            y = self.load(record_path)\n",
    "            image_ = self.create_mel(y, target_fp)\n",
    "        \n",
    "        time_rate = int(image_.shape[1] / 60)\n",
    "        \n",
    "        images = []\n",
    "        \n",
    "        for s in range(0,60,10):\n",
    "            start_sec = s\n",
    "            end_sec   = s + 10\n",
    "\n",
    "            start = int(start_sec * time_rate)\n",
    "            end = int(end_sec * time_rate)\n",
    "        \n",
    "            image = image_[:, start:end, :]\n",
    "                        \n",
    "            height, width, _ = image.shape\n",
    "            image = cv2.resize(image, (self.img_size * 2, self.img_size))\n",
    "            image = np.moveaxis(image, 2, 0)\n",
    "            image = (image / 255.0).astype(np.float32)\n",
    "            \n",
    "            images.append(image)\n",
    "        \n",
    "        species_id = sample['species_id']\n",
    "        target = torch.zeros([24], dtype=torch.float32)\n",
    "        target[species_id] = 1\n",
    "        \n",
    "        return images, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRfcx(Dataset):\n",
    "    def __init__(self, df, path, train=True):\n",
    "        self.df = df\n",
    "        self.path = path\n",
    "        self.train = train\n",
    "        self.img_size = 256\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def get_duration(self, t_min, t_max, duration=10):\n",
    "        annotated_duration = t_max - t_min\n",
    "        \n",
    "        if annotated_duration > duration:\n",
    "            limit_sec = t_max - duration\n",
    "            start_sec = random.randint(t_min, limit_sec)\n",
    "            end_sec = start_sec + duration\n",
    "            \n",
    "            start = start_sec * SR\n",
    "            end = end_sec * SR\n",
    "        else:\n",
    "            res_time = duration - annotated_duration\n",
    "            front_limit = res_time if res_time < t_min else t_min\n",
    "            \n",
    "            front_time = random.randint(0, front_limit)\n",
    "            \n",
    "            back_limit = 60 - t_max\n",
    "            \n",
    "            tmp_time = res_time - front_time\n",
    "            back_time = tmp_time if tmp_time < back_limit else back_limit\n",
    "            \n",
    "            if not tmp_time < back_limit:\n",
    "                front_time += tmp_time - back_limit\n",
    "            \n",
    "            start = (t_min - front_time) * SR\n",
    "            end = (t_max + back_time) * SR\n",
    "            \n",
    "        return start, end\n",
    "    \n",
    "        \n",
    "    def __getitem__(self, idx: int):\n",
    "        sample = self.df.iloc[idx, :]\n",
    "        recording_id = sample['recording_id']\n",
    "        data = torch.load(\n",
    "            self.path + recording_id + '.tensor'\n",
    "        )\n",
    "        \n",
    "        image_ = data\n",
    "            \n",
    "        time_rate = int(image_.shape[1] / 60)\n",
    "        \n",
    "        images = []\n",
    "        \n",
    "        for s in range(0,60,10):\n",
    "            start_sec = s\n",
    "            end_sec   = s + 10\n",
    "\n",
    "            start = int(start_sec * time_rate)\n",
    "            end = int(end_sec * time_rate)\n",
    "        \n",
    "            image = image_[:, start:end, :]\n",
    "            \n",
    "            height, width, _ = image.shape\n",
    "            image = cv2.resize(image, (self.img_size * 2, self.img_size))\n",
    "            image = np.moveaxis(image, 2, 0)\n",
    "            image = (image / 255.0).astype(np.float32)\n",
    "            \n",
    "            images.append(image)\n",
    "        \n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_type, model_name, output_size):\n",
    "        super().__init__()\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        self.mixup_alpha = 0.2\n",
    "        self.random_state = np.random.RandomState(123)\n",
    "        \n",
    "        base_model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\n",
    "        layers = list(base_model.children())[:-1]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "        in_features = base_model.fc.in_features\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(in_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(1024, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"x = x.transpose(1, 2)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 2)\"\"\"\n",
    "        \n",
    "        x = self.encoder(x)\n",
    "            \n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(fold, model, optim, criterion, file_path=\"../../model/\"):\n",
    "    if not TEST_NAME in os.listdir(file_path):\n",
    "        os.mkdir(file_path+TEST_NAME)\n",
    "    \n",
    "    \n",
    "    output_path = file_path + TEST_NAME + '/' + f\"{TEST_NAME}_{fold}.model\"\n",
    "    \n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.cpu().state_dict(),\n",
    "            'optimizer_state_dict': optim.state_dict(),\n",
    "            'criterion': criterion\n",
    "        },\n",
    "        output_path)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LRAP. Instance-level average\n",
    "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
    "def LRAP(preds, labels):\n",
    "    # Ranks of the predictions\n",
    "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
    "    # i, j corresponds to rank of prediction in row i\n",
    "    class_ranks = torch.zeros_like(ranked_classes)\n",
    "    for i in range(ranked_classes.size(0)):\n",
    "        for j in range(ranked_classes.size(1)):\n",
    "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
    "    # Mask out to only use the ranks of relevant GT labels\n",
    "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
    "    # All the GT ranks are in front now\n",
    "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
    "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
    "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
    "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
    "    scores = score_matrix * score_mask_matrix\n",
    "    score = (scores.sum(-1) / labels.sum(-1)).mean()\n",
    "    return score.item()\n",
    "\n",
    "# label-level average\n",
    "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
    "def LWLRAP(preds, labels):\n",
    "    # Ranks of the predictions\n",
    "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
    "    # i, j corresponds to rank of prediction in row i\n",
    "    class_ranks = torch.zeros_like(ranked_classes)\n",
    "    for i in range(ranked_classes.size(0)):\n",
    "        for j in range(ranked_classes.size(1)):\n",
    "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
    "    # Mask out to only use the ranks of relevant GT labels\n",
    "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
    "    # All the GT ranks are in front now\n",
    "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
    "    # Number of GT labels per instance\n",
    "    num_labels = labels.sum(-1)\n",
    "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
    "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
    "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
    "    scores = score_matrix * score_mask_matrix\n",
    "    score = scores.sum() / labels.sum()\n",
    "    return score.item()\n",
    "\n",
    "def mixup_socre(cor, x, y, mix_info):\n",
    "    return cor(x, y) * mix_info['lam'] + cor(x, y[mix_info['index']].squeeze()) * (1-mix_info['lam'])\n",
    "\n",
    "# Sample usage\n",
    "# y_true = torch.tensor(np.array([[1, 1, 0], [1, 0, 1], [0, 0, 1]]))\n",
    "# y_score = torch.tensor(np.random.randn(3, 3))\n",
    "# print(LRAP(y_score, y_true), LWLRAP(y_score, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NAME = 'baseline-pic-res'\n",
    "\n",
    "n_splits = 5\n",
    "random_state = 1\n",
    "epochs = 75\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_params = {\n",
    "    'model_type': 'res', # res or efficientnet\n",
    "    'model_name': 'resnet50',\n",
    "    'output_size': 24,\n",
    "}\n",
    "\n",
    "optim_params = {\n",
    "    'lr': 1e-3,\n",
    "    'weight_decay': 5e-5,\n",
    "    'betas': (0.9, 0.999)\n",
    "}\n",
    "\n",
    "scheduler_params = {\n",
    "    'mode': 'max',\n",
    "    'patience': 1,\n",
    "    'factor': 0.6,\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "pcen_parameters = {\n",
    "    'gain': 0.98,\n",
    "    'bias': 2,\n",
    "    'power': 0.5,\n",
    "    'time_constant': 0.4,\n",
    "    'eps': 0.000001,\n",
    "}\n",
    "\n",
    "train_params = {\n",
    "    'fp': train_fp,\n",
    "    'pcen_parameters': pcen_parameters,\n",
    "    'train': True,\n",
    "    'data_path': '/home/yuigahama/kaggle/rfcx/data/train_noise_v2/'  \n",
    "}\n",
    "\n",
    "val_params = {\n",
    "    'fp': train_fp,\n",
    "    'train': True,\n",
    "    'pcen_parameters': pcen_parameters,\n",
    "    'data_path': '/home/yuigahama/kaggle/rfcx/data/train_wo_fp/'\n",
    "}\n",
    "\n",
    "test_data_params = {\n",
    "    'train': False,\n",
    "    'path': '/home/yuigahama/kaggle/rfcx/data/test_wo_fp/'\n",
    "}\n",
    "\n",
    "dataloder_params = {\n",
    "    'batch_size': 16,\n",
    "    'num_workers': 15,\n",
    "    'pin_memory': False,\n",
    "}\n",
    "\n",
    "test_dataloder_params = {\n",
    "    'batch_size': 32,\n",
    "    'num_workers': 15,\n",
    "    'pin_memory': False,\n",
    "    'shuffle':False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/yuigahama/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- fold 0 ----------\n",
      "epoch   1| T | L: 1.33 | S: 0.213 | C: 85/972 | V | loss: 1.26 | score: 0.268 | C: 23/244 | time: 0:00:20\n",
      "epoch   2| T | L: 1.15 | S: 0.267 | C: 95/972 | V | loss: 1.14 | score: 0.272 | C: 21/244 | time: 0:00:19\n",
      "epoch   3| T | L: 1.11 | S: 0.284 | C: 101/972 | V | loss: 1.13 | score: 0.305 | C: 30/244 | time: 0:00:19\n",
      "epoch   4| T | L: 1.07 | S: 0.296 | C: 110/972 | V | loss: 1.11 | score: 0.3 | C: 31/244 | time: 0:00:19\n",
      "epoch   5| T | L: 1.03 | S: 0.322 | C: 137/972 | V | loss: 1.27 | score: 0.29 | C: 24/244 | time: 0:00:19\n",
      "epoch   6| T | L: 1.02 | S: 0.348 | C: 160/972 | V | loss: 1.07 | score: 0.337 | C: 39/244 | time: 0:00:19\n",
      "epoch   7| T | L: 1.02 | S: 0.36 | C: 173/972 | V | loss: 1.03 | score: 0.339 | C: 38/244 | time: 0:00:19\n",
      "epoch   8| T | L: 0.946 | S: 0.385 | C: 191/972 | V | loss: 1.04 | score: 0.355 | C: 47/244 | time: 0:00:19\n",
      "epoch   9| T | L: 0.929 | S: 0.393 | C: 192/972 | V | loss: 1.2 | score: 0.385 | C: 50/244 | time: 0:00:19\n",
      "epoch  10| T | L: 0.927 | S: 0.391 | C: 183/972 | V | loss: 0.992 | score: 0.394 | C: 52/244 | time: 0:00:20\n",
      "epoch  11| T | L: 0.904 | S: 0.417 | C: 219/972 | V | loss: 1.05 | score: 0.381 | C: 53/244 | time: 0:00:20\n",
      "epoch  12| T | L: 0.873 | S: 0.435 | C: 243/972 | V | loss: 1.1 | score: 0.407 | C: 53/244 | time: 0:00:19\n",
      "epoch  13| T | L: 0.825 | S: 0.467 | C: 276/972 | V | loss: 0.935 | score: 0.461 | C: 74/244 | time: 0:00:19\n",
      "epoch  14| T | L: 0.817 | S: 0.475 | C: 277/972 | V | loss: 1.25 | score: 0.417 | C: 54/244 | time: 0:00:19\n",
      "epoch  15| T | L: 0.816 | S: 0.476 | C: 277/972 | V | loss: 1.18 | score: 0.405 | C: 58/244 | time: 0:00:19\n",
      "epoch  16| T | L: 0.809 | S: 0.495 | C: 300/972 | V | loss: 1.04 | score: 0.464 | C: 68/244 | time: 0:00:19\n",
      "epoch  17| T | L: 0.769 | S: 0.507 | C: 303/972 | V | loss: 1.25 | score: 0.408 | C: 56/244 | time: 0:00:20\n",
      "epoch  18| T | L: 0.785 | S: 0.498 | C: 300/972 | V | loss: 1.16 | score: 0.5 | C: 78/244 | time: 0:00:19\n",
      "epoch  19| T | L: 0.716 | S: 0.528 | C: 331/972 | V | loss: 0.988 | score: 0.532 | C: 83/244 | time: 0:00:19\n",
      "epoch  20| T | L: 0.754 | S: 0.523 | C: 314/972 | V | loss: 0.876 | score: 0.506 | C: 81/244 | time: 0:00:19\n",
      "epoch  21| T | L: 0.708 | S: 0.557 | C: 359/972 | V | loss: 0.951 | score: 0.505 | C: 75/244 | time: 0:00:19\n",
      "epoch  22| T | L: 0.655 | S: 0.572 | C: 372/972 | V | loss: 1.13 | score: 0.547 | C: 89/244 | time: 0:00:20\n",
      "epoch  23| T | L: 0.665 | S: 0.572 | C: 371/972 | V | loss: 0.866 | score: 0.556 | C: 94/244 | time: 0:00:19\n",
      "epoch  24| T | L: 0.669 | S: 0.582 | C: 385/972 | V | loss: 0.923 | score: 0.567 | C: 100/244 | time: 0:00:20\n",
      "epoch  25| T | L: 0.645 | S: 0.601 | C: 411/972 | V | loss: 0.88 | score: 0.542 | C: 90/244 | time: 0:00:20\n",
      "epoch  26| T | L: 0.656 | S: 0.589 | C: 395/972 | V | loss: 1.13 | score: 0.463 | C: 65/244 | time: 0:00:19\n",
      "epoch  27| T | L: 0.596 | S: 0.612 | C: 415/972 | V | loss: 0.894 | score: 0.552 | C: 94/244 | time: 0:00:19\n",
      "epoch  28| T | L: 0.557 | S: 0.646 | C: 455/972 | V | loss: 0.825 | score: 0.57 | C: 101/244 | time: 0:00:19\n",
      "epoch  29| T | L: 0.544 | S: 0.655 | C: 469/972 | V | loss: 0.826 | score: 0.584 | C: 99/244 | time: 0:00:19\n",
      "epoch  30| T | L: 0.574 | S: 0.646 | C: 454/972 | V | loss: 0.899 | score: 0.565 | C: 94/244 | time: 0:00:19\n",
      "epoch  31| T | L: 0.571 | S: 0.648 | C: 453/972 | V | loss: 0.857 | score: 0.607 | C: 108/244 | time: 0:00:19\n",
      "epoch  32| T | L: 0.542 | S: 0.653 | C: 463/972 | V | loss: 0.955 | score: 0.603 | C: 104/244 | time: 0:00:20\n",
      "epoch  33| T | L: 0.498 | S: 0.677 | C: 489/972 | V | loss: 0.888 | score: 0.632 | C: 113/244 | time: 0:00:19\n",
      "epoch  34| T | L: 0.486 | S: 0.685 | C: 500/972 | V | loss: 0.952 | score: 0.614 | C: 106/244 | time: 0:00:19\n",
      "epoch  35| T | L: 0.472 | S: 0.71 | C: 531/972 | V | loss: 1.24 | score: 0.584 | C: 97/244 | time: 0:00:20\n",
      "epoch  36| T | L: 0.474 | S: 0.71 | C: 537/972 | V | loss: 0.83 | score: 0.653 | C: 127/244 | time: 0:00:20\n",
      "epoch  37| T | L: 0.478 | S: 0.702 | C: 520/972 | V | loss: 0.892 | score: 0.654 | C: 123/244 | time: 0:00:19\n",
      "epoch  38| T | L: 0.427 | S: 0.742 | C: 572/972 | V | loss: 1.73 | score: 0.582 | C: 100/244 | time: 0:00:20\n",
      "epoch  39| T | L: 0.448 | S: 0.722 | C: 548/972 | V | loss: 0.925 | score: 0.62 | C: 113/244 | time: 0:00:20\n",
      "epoch  40| T | L: 0.453 | S: 0.72 | C: 547/972 | V | loss: 1.06 | score: 0.642 | C: 118/244 | time: 0:00:19\n",
      "epoch  41| T | L: 0.422 | S: 0.743 | C: 572/972 | V | loss: 1.09 | score: 0.665 | C: 130/244 | time: 0:00:20\n",
      "epoch  42| T | L: 0.407 | S: 0.74 | C: 567/972 | V | loss: 0.944 | score: 0.665 | C: 122/244 | time: 0:00:20\n",
      "epoch  43| T | L: 0.401 | S: 0.76 | C: 597/972 | V | loss: 0.845 | score: 0.652 | C: 120/244 | time: 0:00:19\n",
      "epoch  44| T | L: 0.387 | S: 0.763 | C: 606/972 | V | loss: 0.806 | score: 0.694 | C: 133/244 | time: 0:00:20\n",
      "epoch  45| T | L: 0.388 | S: 0.767 | C: 608/972 | V | loss: 1.23 | score: 0.67 | C: 126/244 | time: 0:00:20\n",
      "epoch  46| T | L: 0.353 | S: 0.764 | C: 596/972 | V | loss: 0.962 | score: 0.689 | C: 137/244 | time: 0:00:19\n",
      "epoch  47| T | L: 0.397 | S: 0.775 | C: 623/972 | V | loss: 1.47 | score: 0.593 | C: 110/244 | time: 0:00:20\n",
      "epoch  48| T | L: 0.383 | S: 0.764 | C: 600/972 | V | loss: 0.775 | score: 0.686 | C: 139/244 | time: 0:00:20\n",
      "epoch  49| T | L: 0.371 | S: 0.774 | C: 613/972 | V | loss: 0.992 | score: 0.695 | C: 136/244 | time: 0:00:20\n",
      "epoch  50| T | L: 0.312 | S: 0.811 | C: 666/972 | V | loss: 1.04 | score: 0.697 | C: 139/244 | time: 0:00:20\n",
      "epoch  51| T | L: 0.318 | S: 0.817 | C: 671/972 | V | loss: 0.924 | score: 0.729 | C: 148/244 | time: 0:00:20\n",
      "epoch  52| T | L: 0.341 | S: 0.8 | C: 651/972 | V | loss: 1.1 | score: 0.691 | C: 140/244 | time: 0:00:20\n",
      "epoch  53| T | L: 0.321 | S: 0.81 | C: 663/972 | V | loss: 1.02 | score: 0.69 | C: 137/244 | time: 0:00:19\n",
      "epoch  54| T | L: 0.304 | S: 0.827 | C: 691/972 | V | loss: 0.751 | score: 0.726 | C: 143/244 | time: 0:00:20\n",
      "epoch  55| T | L: 0.284 | S: 0.826 | C: 684/972 | V | loss: 1.16 | score: 0.698 | C: 141/244 | time: 0:00:19\n",
      "epoch  56| T | L: 0.312 | S: 0.821 | C: 679/972 | V | loss: 0.964 | score: 0.712 | C: 143/244 | time: 0:00:20\n",
      "epoch  57| T | L: 0.283 | S: 0.845 | C: 716/972 | V | loss: 0.88 | score: 0.695 | C: 133/244 | time: 0:00:19\n",
      "epoch  58| T | L: 0.258 | S: 0.847 | C: 712/972 | V | loss: 0.854 | score: 0.708 | C: 142/244 | time: 0:00:19\n",
      "epoch  59| T | L: 0.257 | S: 0.846 | C: 721/972 | V | loss: 1.39 | score: 0.684 | C: 134/244 | time: 0:00:20\n",
      "epoch  60| T | L: 0.288 | S: 0.846 | C: 724/972 | V | loss: 0.964 | score: 0.697 | C: 139/244 | time: 0:00:19\n",
      "epoch  61| T | L: 0.227 | S: 0.855 | C: 720/972 | V | loss: 1.22 | score: 0.701 | C: 136/244 | time: 0:00:20\n",
      "epoch  62| T | L: 0.241 | S: 0.856 | C: 729/972 | V | loss: 1.25 | score: 0.669 | C: 128/244 | time: 0:00:20\n",
      "epoch  63| T | L: 0.243 | S: 0.861 | C: 734/972 | V | loss: 1.02 | score: 0.697 | C: 141/244 | time: 0:00:19\n",
      "epoch  64| T | L: 0.248 | S: 0.862 | C: 740/972 | V | loss: 1.03 | score: 0.684 | C: 135/244 | time: 0:00:19\n",
      "epoch  65| T | L: 0.254 | S: 0.849 | C: 718/972 | V | loss: 0.976 | score: 0.694 | C: 134/244 | time: 0:00:20\n",
      "epoch  66| T | L: 0.258 | S: 0.848 | C: 718/972 | V | loss: 1.17 | score: 0.71 | C: 138/244 | time: 0:00:19\n",
      "epoch  67| T | L: 0.211 | S: 0.868 | C: 743/972 | V | loss: 0.981 | score: 0.736 | C: 149/244 | time: 0:00:20\n",
      "epoch  68| T | L: 0.226 | S: 0.87 | C: 752/972 | V | loss: 1.17 | score: 0.708 | C: 144/244 | time: 0:00:19\n",
      "epoch  69| T | L: 0.196 | S: 0.883 | C: 771/972 | V | loss: 1.09 | score: 0.756 | C: 157/244 | time: 0:00:19\n",
      "epoch  70| T | L: 0.185 | S: 0.894 | C: 791/972 | V | loss: 1.29 | score: 0.733 | C: 144/244 | time: 0:00:20\n",
      "epoch  71| T | L: 0.27 | S: 0.858 | C: 736/972 | V | loss: 0.888 | score: 0.713 | C: 136/244 | time: 0:00:20\n",
      "epoch  72| T | L: 0.231 | S: 0.864 | C: 738/972 | V | loss: 0.963 | score: 0.669 | C: 129/244 | time: 0:00:20\n",
      "epoch  73| T | L: 0.213 | S: 0.874 | C: 752/972 | V | loss: 1.24 | score: 0.705 | C: 138/244 | time: 0:00:19\n",
      "epoch  74| T | L: 0.203 | S: 0.882 | C: 766/972 | V | loss: 1.28 | score: 0.761 | C: 154/244 | time: 0:00:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/yuigahama/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- fold 1 ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/yuigahama/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1| T | L: 1.33 | S: 0.209 | C: 70/973 | V | loss: 1.29 | score: 0.23 | C: 20/243 | time: 0:00:20\n",
      "epoch   2| T | L: 1.15 | S: 0.272 | C: 94/973 | V | loss: 1.42 | score: 0.25 | C: 22/243 | time: 0:00:20\n",
      "epoch   3| T | L: 1.08 | S: 0.286 | C: 103/973 | V | loss: 1.11 | score: 0.294 | C: 26/243 | time: 0:00:20\n",
      "epoch   4| T | L: 1.06 | S: 0.315 | C: 125/973 | V | loss: 1.51 | score: 0.278 | C: 25/243 | time: 0:00:20\n",
      "epoch   5| T | L: 1.03 | S: 0.332 | C: 143/973 | V | loss: 1.46 | score: 0.29 | C: 28/243 | time: 0:00:20\n",
      "epoch   6| T | L: 1.02 | S: 0.328 | C: 134/973 | V | loss: 1.07 | score: 0.301 | C: 29/243 | time: 0:00:20\n",
      "epoch   7| T | L: 1.0 | S: 0.342 | C: 158/973 | V | loss: 1.11 | score: 0.304 | C: 26/243 | time: 0:00:20\n",
      "epoch   8| T | L: 0.987 | S: 0.353 | C: 166/973 | V | loss: 1.08 | score: 0.297 | C: 28/243 | time: 0:00:19\n",
      "epoch   9| T | L: 0.977 | S: 0.348 | C: 154/973 | V | loss: 1.06 | score: 0.318 | C: 32/243 | time: 0:00:20\n",
      "epoch  10| T | L: 0.96 | S: 0.356 | C: 161/973 | V | loss: 0.994 | score: 0.329 | C: 37/243 | time: 0:00:20\n",
      "epoch  11| T | L: 0.944 | S: 0.376 | C: 188/973 | V | loss: 1.07 | score: 0.326 | C: 33/243 | time: 0:00:20\n",
      "epoch  12| T | L: 0.954 | S: 0.372 | C: 181/973 | V | loss: 1.91 | score: 0.32 | C: 39/243 | time: 0:00:20\n",
      "epoch  13| T | L: 0.98 | S: 0.365 | C: 173/973 | V | loss: 1.05 | score: 0.363 | C: 47/243 | time: 0:00:19\n",
      "epoch  14| T | L: 0.927 | S: 0.389 | C: 189/973 | V | loss: 1.14 | score: 0.331 | C: 40/243 | time: 0:00:19\n",
      "epoch  15| T | L: 0.922 | S: 0.392 | C: 188/973 | V | loss: 1.1 | score: 0.334 | C: 33/243 | time: 0:00:19\n",
      "epoch  16| T | L: 0.922 | S: 0.399 | C: 198/973 | V | loss: 1.32 | score: 0.344 | C: 40/243 | time: 0:00:19\n",
      "epoch  17| T | L: 0.907 | S: 0.412 | C: 212/973 | V | loss: 0.98 | score: 0.367 | C: 46/243 | time: 0:00:19\n",
      "epoch  18| T | L: 0.906 | S: 0.429 | C: 231/973 | V | loss: 1.02 | score: 0.393 | C: 47/243 | time: 0:00:19\n",
      "epoch  19| T | L: 0.889 | S: 0.423 | C: 217/973 | V | loss: 1.08 | score: 0.368 | C: 39/243 | time: 0:00:19\n",
      "epoch  20| T | L: 0.863 | S: 0.426 | C: 210/973 | V | loss: 0.96 | score: 0.391 | C: 49/243 | time: 0:00:19\n",
      "epoch  21| T | L: 0.864 | S: 0.44 | C: 237/973 | V | loss: 0.967 | score: 0.391 | C: 51/243 | time: 0:00:19\n",
      "epoch  22| T | L: 0.857 | S: 0.453 | C: 249/973 | V | loss: 1.23 | score: 0.336 | C: 31/243 | time: 0:00:19\n",
      "epoch  23| T | L: 0.877 | S: 0.436 | C: 226/973 | V | loss: 0.988 | score: 0.379 | C: 47/243 | time: 0:00:20\n",
      "epoch  24| T | L: 0.845 | S: 0.467 | C: 256/973 | V | loss: 1.28 | score: 0.379 | C: 50/243 | time: 0:00:20\n",
      "epoch  25| T | L: 0.811 | S: 0.471 | C: 261/973 | V | loss: 0.931 | score: 0.439 | C: 64/243 | time: 0:00:20\n",
      "epoch  26| T | L: 0.839 | S: 0.477 | C: 274/973 | V | loss: 0.86 | score: 0.471 | C: 65/243 | time: 0:00:20\n",
      "epoch  27| T | L: 0.805 | S: 0.491 | C: 287/973 | V | loss: 0.891 | score: 0.448 | C: 62/243 | time: 0:00:20\n",
      "epoch  28| T | L: 0.756 | S: 0.512 | C: 309/973 | V | loss: 0.913 | score: 0.459 | C: 64/243 | time: 0:00:20\n",
      "epoch  29| T | L: 0.768 | S: 0.518 | C: 310/973 | V | loss: 0.854 | score: 0.492 | C: 75/243 | time: 0:00:20\n",
      "epoch  30| T | L: 0.779 | S: 0.505 | C: 297/973 | V | loss: 0.947 | score: 0.453 | C: 68/243 | time: 0:00:20\n",
      "epoch  31| T | L: 0.732 | S: 0.518 | C: 302/973 | V | loss: 0.93 | score: 0.459 | C: 61/243 | time: 0:00:20\n",
      "epoch  32| T | L: 0.737 | S: 0.537 | C: 336/973 | V | loss: 0.817 | score: 0.489 | C: 65/243 | time: 0:00:20\n",
      "epoch  33| T | L: 0.682 | S: 0.566 | C: 366/973 | V | loss: 0.89 | score: 0.499 | C: 74/243 | time: 0:00:20\n",
      "epoch  34| T | L: 0.7 | S: 0.558 | C: 360/973 | V | loss: 0.852 | score: 0.499 | C: 72/243 | time: 0:00:20\n",
      "epoch  35| T | L: 0.712 | S: 0.533 | C: 315/973 | V | loss: 0.857 | score: 0.507 | C: 83/243 | time: 0:00:20\n",
      "epoch  36| T | L: 0.671 | S: 0.577 | C: 379/973 | V | loss: 0.82 | score: 0.534 | C: 78/243 | time: 0:00:20\n",
      "epoch  37| T | L: 0.701 | S: 0.554 | C: 352/973 | V | loss: 0.855 | score: 0.502 | C: 77/243 | time: 0:00:20\n",
      "epoch  38| T | L: 0.673 | S: 0.594 | C: 399/973 | V | loss: 0.827 | score: 0.534 | C: 75/243 | time: 0:00:20\n",
      "epoch  39| T | L: 0.651 | S: 0.591 | C: 392/973 | V | loss: 1.25 | score: 0.508 | C: 76/243 | time: 0:00:20\n",
      "epoch  40| T | L: 0.653 | S: 0.587 | C: 392/973 | V | loss: 0.843 | score: 0.56 | C: 90/243 | time: 0:00:20\n",
      "epoch  41| T | L: 0.615 | S: 0.616 | C: 419/973 | V | loss: 0.86 | score: 0.562 | C: 92/243 | time: 0:00:20\n",
      "epoch  42| T | L: 0.586 | S: 0.613 | C: 416/973 | V | loss: 1.03 | score: 0.519 | C: 81/243 | time: 0:00:20\n",
      "epoch  43| T | L: 0.635 | S: 0.605 | C: 408/973 | V | loss: 0.956 | score: 0.506 | C: 78/243 | time: 0:00:19\n",
      "epoch  44| T | L: 0.594 | S: 0.631 | C: 447/973 | V | loss: 0.801 | score: 0.577 | C: 92/243 | time: 0:00:20\n",
      "epoch  45| T | L: 0.552 | S: 0.643 | C: 453/973 | V | loss: 0.87 | score: 0.583 | C: 102/243 | time: 0:00:20\n",
      "epoch  46| T | L: 0.528 | S: 0.65 | C: 463/973 | V | loss: 0.857 | score: 0.613 | C: 108/243 | time: 0:00:20\n",
      "epoch  47| T | L: 0.547 | S: 0.661 | C: 477/973 | V | loss: 1.26 | score: 0.509 | C: 87/243 | time: 0:00:19\n",
      "epoch  48| T | L: 0.514 | S: 0.663 | C: 477/973 | V | loss: 0.914 | score: 0.6 | C: 106/243 | time: 0:00:20\n",
      "epoch  49| T | L: 0.535 | S: 0.653 | C: 461/973 | V | loss: 0.839 | score: 0.562 | C: 89/243 | time: 0:00:20\n",
      "epoch  50| T | L: 0.514 | S: 0.666 | C: 485/973 | V | loss: 0.782 | score: 0.613 | C: 108/243 | time: 0:00:20\n",
      "epoch  51| T | L: 0.466 | S: 0.7 | C: 518/973 | V | loss: 0.884 | score: 0.601 | C: 103/243 | time: 0:00:20\n",
      "epoch  52| T | L: 0.492 | S: 0.679 | C: 496/973 | V | loss: 0.987 | score: 0.575 | C: 98/243 | time: 0:00:20\n",
      "epoch  53| T | L: 0.471 | S: 0.697 | C: 525/973 | V | loss: 0.938 | score: 0.62 | C: 111/243 | time: 0:00:20\n",
      "epoch  54| T | L: 0.479 | S: 0.69 | C: 510/973 | V | loss: 0.66 | score: 0.632 | C: 107/243 | time: 0:00:20\n",
      "epoch  55| T | L: 0.426 | S: 0.716 | C: 540/973 | V | loss: 0.933 | score: 0.625 | C: 111/243 | time: 0:00:20\n",
      "epoch  56| T | L: 0.456 | S: 0.7 | C: 524/973 | V | loss: 0.839 | score: 0.609 | C: 108/243 | time: 0:00:20\n",
      "epoch  57| T | L: 0.438 | S: 0.726 | C: 563/973 | V | loss: 0.736 | score: 0.602 | C: 104/243 | time: 0:00:20\n",
      "epoch  58| T | L: 0.49 | S: 0.69 | C: 510/973 | V | loss: 0.817 | score: 0.643 | C: 121/243 | time: 0:00:20\n",
      "epoch  59| T | L: 0.415 | S: 0.727 | C: 557/973 | V | loss: 0.825 | score: 0.618 | C: 106/243 | time: 0:00:20\n",
      "epoch  60| T | L: 0.413 | S: 0.736 | C: 570/973 | V | loss: 1.24 | score: 0.606 | C: 105/243 | time: 0:00:20\n",
      "epoch  61| T | L: 0.418 | S: 0.731 | C: 560/973 | V | loss: 0.955 | score: 0.565 | C: 95/243 | time: 0:00:20\n",
      "epoch  62| T | L: 0.408 | S: 0.731 | C: 563/973 | V | loss: 0.732 | score: 0.676 | C: 130/243 | time: 0:00:20\n",
      "epoch  63| T | L: 0.402 | S: 0.73 | C: 557/973 | V | loss: 0.743 | score: 0.641 | C: 119/243 | time: 0:00:20\n",
      "epoch  64| T | L: 0.359 | S: 0.751 | C: 583/973 | V | loss: 0.772 | score: 0.657 | C: 120/243 | time: 0:00:20\n",
      "epoch  65| T | L: 0.395 | S: 0.741 | C: 570/973 | V | loss: 0.812 | score: 0.635 | C: 119/243 | time: 0:00:20\n",
      "epoch  66| T | L: 0.409 | S: 0.74 | C: 568/973 | V | loss: 0.896 | score: 0.621 | C: 115/243 | time: 0:00:20\n",
      "epoch  67| T | L: 0.346 | S: 0.761 | C: 592/973 | V | loss: 1.01 | score: 0.64 | C: 116/243 | time: 0:00:20\n",
      "epoch  68| T | L: 0.34 | S: 0.787 | C: 642/973 | V | loss: 0.85 | score: 0.67 | C: 126/243 | time: 0:00:20\n",
      "epoch  69| T | L: 0.335 | S: 0.786 | C: 630/973 | V | loss: 0.866 | score: 0.702 | C: 138/243 | time: 0:00:20\n",
      "epoch  70| T | L: 0.344 | S: 0.787 | C: 637/973 | V | loss: 1.15 | score: 0.644 | C: 121/243 | time: 0:00:20\n",
      "epoch  71| T | L: 0.382 | S: 0.776 | C: 624/973 | V | loss: 0.814 | score: 0.637 | C: 117/243 | time: 0:00:20\n",
      "epoch  72| T | L: 0.325 | S: 0.792 | C: 640/973 | V | loss: 0.807 | score: 0.697 | C: 137/243 | time: 0:00:20\n",
      "epoch  73| T | L: 0.349 | S: 0.771 | C: 603/973 | V | loss: 0.784 | score: 0.666 | C: 122/243 | time: 0:00:20\n",
      "epoch  74| T | L: 0.332 | S: 0.782 | C: 628/973 | V | loss: 0.991 | score: 0.68 | C: 132/243 | time: 0:00:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/yuigahama/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- fold 2 ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/yuigahama/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1| T | L: 1.31 | S: 0.224 | C: 73/973 | V | loss: 1.56 | score: 0.238 | C: 14/243 | time: 0:00:20\n",
      "epoch   2| T | L: 1.16 | S: 0.273 | C: 97/973 | V | loss: 1.2 | score: 0.255 | C: 22/243 | time: 0:00:20\n",
      "epoch   3| T | L: 1.11 | S: 0.283 | C: 110/973 | V | loss: 1.14 | score: 0.247 | C: 19/243 | time: 0:00:20\n",
      "epoch   4| T | L: 1.07 | S: 0.295 | C: 110/973 | V | loss: 1.16 | score: 0.252 | C: 22/243 | time: 0:00:20\n",
      "epoch   5| T | L: 1.06 | S: 0.312 | C: 127/973 | V | loss: 1.18 | score: 0.306 | C: 28/243 | time: 0:00:20\n",
      "epoch   6| T | L: 1.02 | S: 0.305 | C: 108/973 | V | loss: 1.09 | score: 0.306 | C: 33/243 | time: 0:00:20\n",
      "epoch   7| T | L: 1.01 | S: 0.326 | C: 130/973 | V | loss: 1.21 | score: 0.29 | C: 28/243 | time: 0:00:20\n",
      "epoch   8| T | L: 1.0 | S: 0.322 | C: 128/973 | V | loss: 1.26 | score: 0.241 | C: 16/243 | time: 0:00:20\n",
      "epoch   9| T | L: 1.03 | S: 0.32 | C: 127/973 | V | loss: 1.23 | score: 0.317 | C: 32/243 | time: 0:00:20\n",
      "epoch  10| T | L: 1.01 | S: 0.348 | C: 159/973 | V | loss: 1.26 | score: 0.275 | C: 26/243 | time: 0:00:20\n",
      "epoch  11| T | L: 0.994 | S: 0.352 | C: 159/973 | V | loss: 1.2 | score: 0.318 | C: 36/243 | time: 0:00:20\n",
      "epoch  12| T | L: 1.0 | S: 0.35 | C: 154/973 | V | loss: 1.25 | score: 0.319 | C: 34/243 | time: 0:00:20\n",
      "epoch  13| T | L: 0.968 | S: 0.362 | C: 167/973 | V | loss: 1.2 | score: 0.343 | C: 41/243 | time: 0:00:20\n",
      "epoch  14| T | L: 0.944 | S: 0.366 | C: 170/973 | V | loss: 1.29 | score: 0.352 | C: 38/243 | time: 0:00:20\n",
      "epoch  15| T | L: 0.913 | S: 0.385 | C: 183/973 | V | loss: 1.31 | score: 0.358 | C: 41/243 | time: 0:00:20\n",
      "epoch  16| T | L: 0.941 | S: 0.379 | C: 174/973 | V | loss: 1.1 | score: 0.333 | C: 34/243 | time: 0:00:20\n",
      "epoch  17| T | L: 0.915 | S: 0.406 | C: 209/973 | V | loss: 1.13 | score: 0.378 | C: 47/243 | time: 0:00:20\n",
      "epoch  18| T | L: 0.924 | S: 0.403 | C: 201/973 | V | loss: 1.26 | score: 0.342 | C: 36/243 | time: 0:00:19\n",
      "epoch  19| T | L: 0.9 | S: 0.417 | C: 216/973 | V | loss: 1.05 | score: 0.366 | C: 42/243 | time: 0:00:19\n",
      "epoch  20| T | L: 0.873 | S: 0.433 | C: 226/973 | V | loss: 1.02 | score: 0.365 | C: 44/243 | time: 0:00:19\n",
      "epoch  21| T | L: 0.891 | S: 0.414 | C: 207/973 | V | loss: 1.11 | score: 0.413 | C: 54/243 | time: 0:00:20\n",
      "epoch  22| T | L: 0.853 | S: 0.453 | C: 252/973 | V | loss: 1.19 | score: 0.359 | C: 40/243 | time: 0:00:20\n",
      "epoch  23| T | L: 0.855 | S: 0.443 | C: 234/973 | V | loss: 1.05 | score: 0.397 | C: 52/243 | time: 0:00:20\n",
      "epoch  24| T | L: 0.815 | S: 0.442 | C: 231/973 | V | loss: 1.18 | score: 0.393 | C: 51/243 | time: 0:00:20\n",
      "epoch  25| T | L: 0.848 | S: 0.437 | C: 233/973 | V | loss: 1.11 | score: 0.404 | C: 57/243 | time: 0:00:20\n",
      "epoch  26| T | L: 0.85 | S: 0.452 | C: 244/973 | V | loss: 1.07 | score: 0.4 | C: 51/243 | time: 0:00:20\n",
      "epoch  27| T | L: 0.812 | S: 0.471 | C: 261/973 | V | loss: 1.08 | score: 0.418 | C: 55/243 | time: 0:00:20\n",
      "epoch  28| T | L: 0.788 | S: 0.46 | C: 248/973 | V | loss: 1.28 | score: 0.389 | C: 45/243 | time: 0:00:20\n",
      "epoch  29| T | L: 0.793 | S: 0.487 | C: 279/973 | V | loss: 1.09 | score: 0.433 | C: 60/243 | time: 0:00:20\n",
      "epoch  30| T | L: 0.786 | S: 0.485 | C: 274/973 | V | loss: 1.12 | score: 0.397 | C: 51/243 | time: 0:00:19\n",
      "epoch  31| T | L: 0.77 | S: 0.481 | C: 264/973 | V | loss: 1.08 | score: 0.416 | C: 55/243 | time: 0:00:20\n",
      "epoch  32| T | L: 0.754 | S: 0.491 | C: 276/973 | V | loss: 1.16 | score: 0.442 | C: 65/243 | time: 0:00:20\n",
      "epoch  33| T | L: 0.781 | S: 0.468 | C: 254/973 | V | loss: 1.13 | score: 0.437 | C: 68/243 | time: 0:00:20\n",
      "epoch  34| T | L: 0.76 | S: 0.506 | C: 293/973 | V | loss: 1.14 | score: 0.388 | C: 45/243 | time: 0:00:20\n",
      "epoch  35| T | L: 0.742 | S: 0.511 | C: 299/973 | V | loss: 1.26 | score: 0.412 | C: 55/243 | time: 0:00:20\n",
      "epoch  36| T | L: 0.727 | S: 0.51 | C: 303/973 | V | loss: 1.13 | score: 0.346 | C: 47/243 | time: 0:00:20\n",
      "epoch  37| T | L: 0.724 | S: 0.518 | C: 308/973 | V | loss: 1.23 | score: 0.425 | C: 57/243 | time: 0:00:20\n",
      "epoch  38| T | L: 0.704 | S: 0.53 | C: 321/973 | V | loss: 2.04 | score: 0.382 | C: 50/243 | time: 0:00:20\n",
      "epoch  39| T | L: 0.72 | S: 0.524 | C: 318/973 | V | loss: 1.2 | score: 0.433 | C: 64/243 | time: 0:00:20\n",
      "epoch  40| T | L: 0.718 | S: 0.513 | C: 301/973 | V | loss: 0.985 | score: 0.468 | C: 66/243 | time: 0:00:20\n",
      "epoch  41| T | L: 0.698 | S: 0.544 | C: 333/973 | V | loss: 1.08 | score: 0.446 | C: 66/243 | time: 0:00:20\n",
      "epoch  42| T | L: 0.682 | S: 0.541 | C: 325/973 | V | loss: 1.16 | score: 0.431 | C: 57/243 | time: 0:00:20\n",
      "epoch  43| T | L: 0.678 | S: 0.538 | C: 323/973 | V | loss: 1.12 | score: 0.478 | C: 80/243 | time: 0:00:20\n",
      "epoch  44| T | L: 0.671 | S: 0.556 | C: 350/973 | V | loss: 1.02 | score: 0.465 | C: 72/243 | time: 0:00:20\n",
      "epoch  45| T | L: 0.659 | S: 0.567 | C: 360/973 | V | loss: 1.11 | score: 0.494 | C: 80/243 | time: 0:00:19\n",
      "epoch  46| T | L: 0.642 | S: 0.558 | C: 333/973 | V | loss: 1.07 | score: 0.488 | C: 80/243 | time: 0:00:20\n",
      "epoch  47| T | L: 0.634 | S: 0.562 | C: 346/973 | V | loss: 1.0 | score: 0.512 | C: 86/243 | time: 0:00:20\n",
      "epoch  48| T | L: 0.634 | S: 0.571 | C: 366/973 | V | loss: 1.08 | score: 0.425 | C: 60/243 | time: 0:00:20\n",
      "epoch  49| T | L: 0.62 | S: 0.586 | C: 376/973 | V | loss: 1.0 | score: 0.494 | C: 79/243 | time: 0:00:20\n",
      "epoch  50| T | L: 0.603 | S: 0.594 | C: 385/973 | V | loss: 1.1 | score: 0.502 | C: 81/243 | time: 0:00:20\n",
      "epoch  51| T | L: 0.561 | S: 0.606 | C: 393/973 | V | loss: 1.23 | score: 0.472 | C: 72/243 | time: 0:00:20\n",
      "epoch  52| T | L: 0.577 | S: 0.611 | C: 403/973 | V | loss: 1.03 | score: 0.474 | C: 69/243 | time: 0:00:20\n",
      "epoch  53| T | L: 0.647 | S: 0.586 | C: 385/973 | V | loss: 1.05 | score: 0.48 | C: 69/243 | time: 0:00:20\n",
      "epoch  54| T | L: 0.572 | S: 0.624 | C: 425/973 | V | loss: 1.22 | score: 0.485 | C: 75/243 | time: 0:00:20\n",
      "epoch  55| T | L: 0.573 | S: 0.625 | C: 424/973 | V | loss: 1.22 | score: 0.498 | C: 83/243 | time: 0:00:20\n",
      "epoch  56| T | L: 0.549 | S: 0.636 | C: 432/973 | V | loss: 1.35 | score: 0.455 | C: 69/243 | time: 0:00:20\n",
      "epoch  57| T | L: 0.537 | S: 0.649 | C: 458/973 | V | loss: 1.26 | score: 0.483 | C: 82/243 | time: 0:00:20\n",
      "epoch  58| T | L: 0.556 | S: 0.644 | C: 448/973 | V | loss: 1.21 | score: 0.497 | C: 80/243 | time: 0:00:19\n",
      "epoch  59| T | L: 0.51 | S: 0.654 | C: 459/973 | V | loss: 1.2 | score: 0.501 | C: 81/243 | time: 0:00:20\n",
      "epoch  60| T | L: 0.493 | S: 0.655 | C: 454/973 | V | loss: 1.29 | score: 0.522 | C: 88/243 | time: 0:00:20\n",
      "epoch  61| T | L: 0.487 | S: 0.681 | C: 495/973 | V | loss: 1.23 | score: 0.527 | C: 88/243 | time: 0:00:20\n",
      "epoch  62| T | L: 0.523 | S: 0.654 | C: 454/973 | V | loss: 1.47 | score: 0.437 | C: 65/243 | time: 0:00:20\n",
      "epoch  63| T | L: 0.491 | S: 0.671 | C: 482/973 | V | loss: 1.2 | score: 0.508 | C: 85/243 | time: 0:00:20\n",
      "epoch  64| T | L: 0.477 | S: 0.672 | C: 475/973 | V | loss: 1.02 | score: 0.542 | C: 93/243 | time: 0:00:20\n",
      "epoch  65| T | L: 0.455 | S: 0.696 | C: 505/973 | V | loss: 1.51 | score: 0.482 | C: 73/243 | time: 0:00:20\n",
      "epoch  66| T | L: 0.491 | S: 0.675 | C: 489/973 | V | loss: 1.15 | score: 0.534 | C: 91/243 | time: 0:00:19\n",
      "epoch  67| T | L: 0.457 | S: 0.674 | C: 476/973 | V | loss: 1.36 | score: 0.501 | C: 87/243 | time: 0:00:19\n",
      "epoch  68| T | L: 0.471 | S: 0.688 | C: 497/973 | V | loss: 1.2 | score: 0.517 | C: 87/243 | time: 0:00:20\n",
      "epoch  69| T | L: 0.431 | S: 0.7 | C: 513/973 | V | loss: 1.48 | score: 0.526 | C: 89/243 | time: 0:00:20\n",
      "epoch  70| T | L: 0.435 | S: 0.698 | C: 508/973 | V | loss: 1.1 | score: 0.561 | C: 96/243 | time: 0:00:20\n",
      "epoch  71| T | L: 0.448 | S: 0.705 | C: 523/973 | V | loss: 1.37 | score: 0.528 | C: 92/243 | time: 0:00:19\n",
      "epoch  72| T | L: 0.439 | S: 0.711 | C: 531/973 | V | loss: 1.3 | score: 0.486 | C: 77/243 | time: 0:00:20\n",
      "epoch  73| T | L: 0.426 | S: 0.706 | C: 522/973 | V | loss: 1.12 | score: 0.543 | C: 95/243 | time: 0:00:20\n",
      "epoch  74| T | L: 0.48 | S: 0.69 | C: 504/973 | V | loss: 1.49 | score: 0.467 | C: 74/243 | time: 0:00:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/yuigahama/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- fold 3 ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/yuigahama/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1| T | L: 1.35 | S: 0.204 | C: 75/973 | V | loss: 1.35 | score: 0.231 | C: 22/243 | time: 0:00:20\n",
      "epoch   2| T | L: 1.35 | S: 0.207 | C: 72/973 | V | loss: 1.44 | score: 0.217 | C: 20/243 | time: 0:00:20\n",
      "epoch   3| T | L: 1.34 | S: 0.206 | C: 75/973 | V | loss: 1.34 | score: 0.219 | C: 20/243 | time: 0:00:20\n",
      "epoch   4| T | L: 1.31 | S: 0.215 | C: 77/973 | V | loss: 1.33 | score: 0.236 | C: 20/243 | time: 0:00:20\n",
      "epoch   5| T | L: 1.29 | S: 0.226 | C: 70/973 | V | loss: 1.29 | score: 0.213 | C: 15/243 | time: 0:00:20\n",
      "epoch   6| T | L: 1.28 | S: 0.243 | C: 88/973 | V | loss: 1.28 | score: 0.234 | C: 18/243 | time: 0:00:20\n",
      "epoch   7| T | L: 1.25 | S: 0.262 | C: 95/973 | V | loss: 1.26 | score: 0.248 | C: 19/243 | time: 0:00:20\n",
      "epoch   8| T | L: 1.19 | S: 0.266 | C: 89/973 | V | loss: 1.16 | score: 0.286 | C: 24/243 | time: 0:00:20\n",
      "epoch   9| T | L: 1.13 | S: 0.281 | C: 97/973 | V | loss: 1.13 | score: 0.276 | C: 22/243 | time: 0:00:20\n",
      "epoch  10| T | L: 1.14 | S: 0.278 | C: 91/973 | V | loss: 1.09 | score: 0.285 | C: 26/243 | time: 0:00:19\n",
      "epoch  11| T | L: 1.1 | S: 0.266 | C: 77/973 | V | loss: 1.09 | score: 0.282 | C: 24/243 | time: 0:00:20\n",
      "epoch  12| T | L: 1.09 | S: 0.287 | C: 102/973 | V | loss: 1.07 | score: 0.288 | C: 25/243 | time: 0:00:20\n",
      "epoch  13| T | L: 1.1 | S: 0.292 | C: 108/973 | V | loss: 1.12 | score: 0.284 | C: 20/243 | time: 0:00:20\n",
      "epoch  14| T | L: 1.08 | S: 0.289 | C: 103/973 | V | loss: 1.04 | score: 0.291 | C: 24/243 | time: 0:00:20\n",
      "epoch  15| T | L: 1.08 | S: 0.287 | C: 98/973 | V | loss: 1.07 | score: 0.306 | C: 29/243 | time: 0:00:20\n",
      "epoch  16| T | L: 1.1 | S: 0.292 | C: 103/973 | V | loss: 1.05 | score: 0.278 | C: 23/243 | time: 0:00:20\n",
      "epoch  17| T | L: 1.07 | S: 0.292 | C: 99/973 | V | loss: 1.07 | score: 0.304 | C: 26/243 | time: 0:00:20\n",
      "epoch  18| T | L: 1.07 | S: 0.29 | C: 100/973 | V | loss: 1.07 | score: 0.307 | C: 25/243 | time: 0:00:20\n",
      "epoch  19| T | L: 1.06 | S: 0.3 | C: 106/973 | V | loss: 1.03 | score: 0.311 | C: 30/243 | time: 0:00:20\n",
      "epoch  20| T | L: 1.05 | S: 0.29 | C: 88/973 | V | loss: 1.06 | score: 0.303 | C: 30/243 | time: 0:00:20\n",
      "epoch  21| T | L: 1.06 | S: 0.301 | C: 109/973 | V | loss: 1.09 | score: 0.301 | C: 26/243 | time: 0:00:19\n",
      "epoch  22| T | L: 1.04 | S: 0.314 | C: 129/973 | V | loss: 1.08 | score: 0.304 | C: 30/243 | time: 0:00:20\n",
      "epoch  23| T | L: 1.05 | S: 0.307 | C: 111/973 | V | loss: 1.04 | score: 0.316 | C: 27/243 | time: 0:00:20\n",
      "epoch  24| T | L: 1.05 | S: 0.311 | C: 118/973 | V | loss: 1.11 | score: 0.285 | C: 28/243 | time: 0:00:20\n",
      "epoch  25| T | L: 1.04 | S: 0.31 | C: 111/973 | V | loss: 1.04 | score: 0.32 | C: 31/243 | time: 0:00:20\n",
      "epoch  26| T | L: 0.997 | S: 0.323 | C: 118/973 | V | loss: 1.06 | score: 0.302 | C: 29/243 | time: 0:00:20\n",
      "epoch  27| T | L: 1.04 | S: 0.31 | C: 114/973 | V | loss: 1.01 | score: 0.307 | C: 26/243 | time: 0:00:20\n",
      "epoch  28| T | L: 1.01 | S: 0.328 | C: 137/973 | V | loss: 1.04 | score: 0.318 | C: 33/243 | time: 0:00:20\n",
      "epoch  29| T | L: 1.02 | S: 0.319 | C: 119/973 | V | loss: 0.991 | score: 0.312 | C: 29/243 | time: 0:00:20\n",
      "epoch  30| T | L: 1.01 | S: 0.33 | C: 130/973 | V | loss: 0.987 | score: 0.316 | C: 29/243 | time: 0:00:20\n",
      "epoch  31| T | L: 0.995 | S: 0.329 | C: 124/973 | V | loss: 1.01 | score: 0.333 | C: 34/243 | time: 0:00:20\n",
      "epoch  32| T | L: 0.966 | S: 0.342 | C: 144/973 | V | loss: 1.0 | score: 0.316 | C: 32/243 | time: 0:00:20\n",
      "epoch  33| T | L: 0.994 | S: 0.344 | C: 148/973 | V | loss: 1.03 | score: 0.305 | C: 27/243 | time: 0:00:20\n",
      "epoch  34| T | L: 0.971 | S: 0.342 | C: 141/973 | V | loss: 1.11 | score: 0.288 | C: 26/243 | time: 0:00:20\n",
      "epoch  35| T | L: 0.99 | S: 0.338 | C: 140/973 | V | loss: 0.997 | score: 0.361 | C: 39/243 | time: 0:00:20\n",
      "epoch  36| T | L: 0.982 | S: 0.34 | C: 140/973 | V | loss: 1.05 | score: 0.311 | C: 30/243 | time: 0:00:20\n",
      "epoch  37| T | L: 0.965 | S: 0.354 | C: 152/973 | V | loss: 1.03 | score: 0.357 | C: 36/243 | time: 0:00:20\n"
     ]
    }
   ],
   "source": [
    "tta = np.zeros((len(submission), 24))\n",
    "cv_score = 0\n",
    "\n",
    "for fold_id, (train_index, val_index) in enumerate(skf.split(train_tp, train_tp.species_id)):\n",
    "    print(f'---------- fold {fold_id} ----------')\n",
    "    \n",
    "    model = BaseModel(**model_params).to(device)\n",
    "    optim = Adam(model.parameters(), **optim_params)\n",
    "    #scheduler = lr_scheduler.ReduceLROnPlateau(optimizer=optim, **scheduler_params)\n",
    "    scheduler = lr_scheduler.CosineAnnealingLR(optimizer=optim, T_max=10)\n",
    "    \n",
    "    pos_weights = torch.ones(24)\n",
    "    pos_weights = pos_weights * 24\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "    \n",
    "    train_dataset = RfcxDataSet(train_tp.iloc[train_index], **train_params)\n",
    "    val_dataset   = RfcxDataSet(train_tp.iloc[val_index], **val_params)\n",
    "    test_dataset  = SimpleRfcx(submission, **test_data_params)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, shuffle=True, **dataloder_params)\n",
    "    val_dataloader = DataLoader(val_dataset, shuffle=False, **dataloder_params)\n",
    "    test_dataloader = DataLoader(test_dataset, **test_dataloder_params)\n",
    "    \n",
    "    es = 15\n",
    "    for epoch in range(1, epochs):\n",
    "        if es == 0:\n",
    "            break\n",
    "        \n",
    "        start_time = time.time()\n",
    "        bast_score = 0\n",
    "        \n",
    "        # train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_score = 0\n",
    "        train_corr = 0\n",
    "        \n",
    "        for data in train_dataloader:\n",
    "            image = data[0].float().to(device)\n",
    "            label = data[1]\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            output = model(image)\n",
    "            \n",
    "\n",
    "            loss = criterion(output.cpu(), label)\n",
    "            score = LWLRAP(torch.sigmoid(output).cpu(), label)\n",
    "            \n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            vals, answers = torch.max(output, 1)\n",
    "            vals, targets = torch.max(label, 1)\n",
    "            corrects = 0\n",
    "            for i in range(0, len(answers)):\n",
    "                if answers[i] == targets[i]:\n",
    "                    corrects = corrects + 1\n",
    "                    \n",
    "            \n",
    "            train_corr += corrects\n",
    "            train_loss += loss.item()\n",
    "            train_score += score\n",
    "            \n",
    "        train_loss  /= len(train_dataloader)\n",
    "        train_score /= len(train_dataloader)\n",
    "        \n",
    "        # val\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_score = 0\n",
    "        val_corr = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for val_data in val_dataloader:\n",
    "                '''target = val_data[1]\n",
    "                num = len(val_data[0])\n",
    "                label = val_data[1]\n",
    "                tmp = torch.zeros((val_data[0][0].size(0), 24))\n",
    "                \n",
    "                for img in val_data[0]:\n",
    "                    output = model(img.to(device))\n",
    "                    tmp += output.cpu() / num'''\n",
    "                \n",
    "                image = val_data[0].float().to(device)\n",
    "                label = val_data[1]\n",
    "\n",
    "                output = model(image)\n",
    "                    \n",
    "                vals, answers = torch.max(output, 1)\n",
    "                vals, targets = torch.max(label, 1)\n",
    "                corrects = 0\n",
    "                for i in range(0, len(answers)):\n",
    "                    if answers[i] == targets[i]:\n",
    "                        corrects = corrects + 1\n",
    "\n",
    "                val_corr += corrects\n",
    "                val_loss += criterion(output.cpu(), label).item()\n",
    "                val_score += LWLRAP(torch.sigmoid(output).cpu(), label)\n",
    "                \n",
    "        val_loss  /= len(val_dataloader)\n",
    "        val_score /= len(val_dataloader)\n",
    "        \n",
    "        duration = str(datetime.timedelta(seconds=time.time() - start_time))[:7]\n",
    "        print(f'epoch {epoch:3}| T | L: {train_loss:.3} | S: {train_score:.3} | C: {train_corr}/{len(train_dataset)} | V | loss: {val_loss:.3} | score: {val_score:.3} | C: {val_corr}/{len(val_dataset)} | time: {duration}')\n",
    "\n",
    "        if bast_score < val_score:\n",
    "            bast_score = val_score\n",
    "            bast_path = save(fold_id, model, optim, criterion)\n",
    "        else:\n",
    "            es -= 1\n",
    "        \n",
    "        scheduler.step(val_score)\n",
    "            \n",
    "        \n",
    "    oof = np.zeros((len(test_dataset), 24))\n",
    "    model = BaseModel(**model_params).to(device)\n",
    "    \n",
    "    bast_model_parms = torch.load(bast_path)\n",
    "    model.load_state_dict(bast_model_parms['model_state_dict'])\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        start = 0\n",
    "        for i, test_data in enumerate(test_dataloader):\n",
    "            start = 0\n",
    "            target_size = test_data[0].size(0)\n",
    "            for d in test_data:\n",
    "                image = d.float().to(device)\n",
    "                end = start + target_size\n",
    "            \n",
    "                output = model(image)\n",
    "\n",
    "            output = torch.sigmoid(output)\n",
    "            output = output.detach().cpu().numpy()\n",
    "            \n",
    "            oof[start:end, :] = output\n",
    "            start = end\n",
    "            \n",
    "    tta += (oof / n_splits)\n",
    "    \n",
    "    del model, train_dataset, val_dataset, test_dataset, train_dataloader, val_dataloader, test_dataloader\n",
    "    del bast_model_parms, optim\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s0</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>...</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>s22</th>\n",
       "      <th>s23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.445695</td>\n",
       "      <td>0.533450</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.403188</td>\n",
       "      <td>0.435533</td>\n",
       "      <td>0.120745</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.015439</td>\n",
       "      <td>0.575393</td>\n",
       "      <td>0.043221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144612</td>\n",
       "      <td>0.057418</td>\n",
       "      <td>0.056819</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>0.602144</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.398680</td>\n",
       "      <td>0.111421</td>\n",
       "      <td>0.131720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.201426</td>\n",
       "      <td>0.044273</td>\n",
       "      <td>0.329872</td>\n",
       "      <td>0.372739</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.564328</td>\n",
       "      <td>0.394738</td>\n",
       "      <td>0.043304</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.162767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140225</td>\n",
       "      <td>0.125184</td>\n",
       "      <td>0.034053</td>\n",
       "      <td>0.237484</td>\n",
       "      <td>0.086417</td>\n",
       "      <td>0.380273</td>\n",
       "      <td>0.151399</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.406527</td>\n",
       "      <td>0.478254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017627</td>\n",
       "      <td>0.036188</td>\n",
       "      <td>0.091064</td>\n",
       "      <td>0.425175</td>\n",
       "      <td>0.031050</td>\n",
       "      <td>0.193798</td>\n",
       "      <td>0.468982</td>\n",
       "      <td>0.373206</td>\n",
       "      <td>0.010106</td>\n",
       "      <td>0.503285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265688</td>\n",
       "      <td>0.327697</td>\n",
       "      <td>0.184743</td>\n",
       "      <td>0.670946</td>\n",
       "      <td>0.009635</td>\n",
       "      <td>0.224816</td>\n",
       "      <td>0.405624</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.187714</td>\n",
       "      <td>0.367208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.382605</td>\n",
       "      <td>0.257048</td>\n",
       "      <td>0.142256</td>\n",
       "      <td>0.518494</td>\n",
       "      <td>0.125351</td>\n",
       "      <td>0.665855</td>\n",
       "      <td>0.113524</td>\n",
       "      <td>0.229342</td>\n",
       "      <td>0.275768</td>\n",
       "      <td>0.223545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278501</td>\n",
       "      <td>0.200804</td>\n",
       "      <td>0.145173</td>\n",
       "      <td>0.171095</td>\n",
       "      <td>0.205457</td>\n",
       "      <td>0.136477</td>\n",
       "      <td>0.094496</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.296206</td>\n",
       "      <td>0.394871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035332</td>\n",
       "      <td>0.024020</td>\n",
       "      <td>0.074555</td>\n",
       "      <td>0.436384</td>\n",
       "      <td>0.028268</td>\n",
       "      <td>0.327446</td>\n",
       "      <td>0.317773</td>\n",
       "      <td>0.703383</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>0.458428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224739</td>\n",
       "      <td>0.362348</td>\n",
       "      <td>0.140191</td>\n",
       "      <td>0.498871</td>\n",
       "      <td>0.017267</td>\n",
       "      <td>0.212362</td>\n",
       "      <td>0.254635</td>\n",
       "      <td>0.007153</td>\n",
       "      <td>0.426913</td>\n",
       "      <td>0.577057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1992 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            s0        s1        s2        s3        s4        s5        s6  \\\n",
       "0     0.445695  0.533450  0.004240  0.403188  0.435533  0.120745  0.001689   \n",
       "1     0.201426  0.044273  0.329872  0.372739  0.002411  0.564328  0.394738   \n",
       "2     0.017627  0.036188  0.091064  0.425175  0.031050  0.193798  0.468982   \n",
       "3     0.382605  0.257048  0.142256  0.518494  0.125351  0.665855  0.113524   \n",
       "4     0.035332  0.024020  0.074555  0.436384  0.028268  0.327446  0.317773   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1987  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1988  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1989  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1990  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1991  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "            s7        s8        s9  ...       s14       s15       s16  \\\n",
       "0     0.015439  0.575393  0.043221  ...  0.144612  0.057418  0.056819   \n",
       "1     0.043304  0.004310  0.162767  ...  0.140225  0.125184  0.034053   \n",
       "2     0.373206  0.010106  0.503285  ...  0.265688  0.327697  0.184743   \n",
       "3     0.229342  0.275768  0.223545  ...  0.278501  0.200804  0.145173   \n",
       "4     0.703383  0.011371  0.458428  ...  0.224739  0.362348  0.140191   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1987  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1988  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1989  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1990  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1991  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "           s17       s18       s19       s20       s21       s22       s23  \n",
       "0     0.007540  0.602144  0.004007  0.003464  0.398680  0.111421  0.131720  \n",
       "1     0.237484  0.086417  0.380273  0.151399  0.001576  0.406527  0.478254  \n",
       "2     0.670946  0.009635  0.224816  0.405624  0.001498  0.187714  0.367208  \n",
       "3     0.171095  0.205457  0.136477  0.094496  0.088500  0.296206  0.394871  \n",
       "4     0.498871  0.017267  0.212362  0.254635  0.007153  0.426913  0.577057  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1987  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1988  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1989  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1990  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1991  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[1992 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sub = pd.DataFrame(tta, columns=pred_target)\n",
    "pred_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([submission['recording_id'], pred_sub], axis=1).to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
