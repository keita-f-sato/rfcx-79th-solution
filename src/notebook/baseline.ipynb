{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuigahama/anaconda3/lib/python3.8/site-packages/torchaudio/backend/utils.py:53: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, AdamW, lr_scheduler\n",
    "from torch.distributions import Uniform\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchaudio.transforms import Spectrogram, MelSpectrogram\n",
    "from torchaudio.transforms import TimeStretch, AmplitudeToDB, ComplexNorm, Resample\n",
    "from torchaudio.transforms import FrequencyMasking, TimeMasking\n",
    "\n",
    "\"\"\"from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "\"\"\"\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchvision.models import resnet34, resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tp = pd.read_csv('../../data/train_tp.csv')\n",
    "\n",
    "SR = 22050\n",
    "LEN_10SEC = SR * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = False  # type: ignore\n",
    "set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RfcxDataSet(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, data_path:str):\n",
    "        self.df =  df\n",
    "        self.path = data_path\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        sample = self.df.iloc[idx, :]\n",
    "        recording_id = sample['recording_id']\n",
    "        species_id = sample['species_id']\n",
    "        \n",
    "        record_path = self.path + recording_id + '.tensor'\n",
    "        sound_tensor = torch.load(record_path)\n",
    "        \n",
    "        limit_sec = sound_tensor.size(0) - (SR * 10)\n",
    "        \n",
    "        start = random.randint(0, limit_sec)\n",
    "        end = start + (SR * 10)\n",
    "        \n",
    "        target = torch.zeros([24], dtype=torch.float32)\n",
    "        target[species_id] = 1\n",
    "\n",
    "        return sound_tensor[start:end], target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, pool=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        padding = kernel_size // 2\n",
    "        self.pool = pool\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels + in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.zeros_(m.bias)\n",
    "        \n",
    "    def forward(self, x): # x.shape = [batch_size, in_channels, a, b]\n",
    "        x1 = self.conv1(x)\n",
    "        x = self.conv2(torch.cat([x, x1],1))\n",
    "        if(self.pool): x = F.avg_pool2d(x, 2)\n",
    "        return x   # x.shape = [batch_size, out_channels, a//2, b//2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RondomStretchMelSpectrogram(nn.Module):\n",
    "    def __init__(self, sample_rate, n_fft, top_db, max_perc):\n",
    "        super().__init__()\n",
    "        self.time_stretch = TimeStretch(hop_length=None, n_freq=n_fft//2+1)\n",
    "        self.stft = Spectrogram(n_fft=n_fft, power=None)\n",
    "        self.com_norm = ComplexNorm(power=2.)\n",
    "        self.fm = FrequencyMasking(100)\n",
    "        self.tm = TimeMasking(100)\n",
    "        self.mel_specgram = MelSpectrogram(sample_rate, n_fft=n_fft, f_max=8000)\n",
    "        self.AtoDB= AmplitudeToDB(top_db=top_db)\n",
    "        self.max_perc = max_perc\n",
    "        self.sample_rate = sample_rate\n",
    "        self.resamples = [\n",
    "                Resample(sample_rate, sample_rate*0.6),\n",
    "                Resample(sample_rate, sample_rate*0.7),\n",
    "                Resample(sample_rate, sample_rate*0.8),\n",
    "                Resample(sample_rate, sample_rate*0.9),\n",
    "                Resample(sample_rate, sample_rate*1),\n",
    "                Resample(sample_rate, sample_rate*1.1),\n",
    "                Resample(sample_rate, sample_rate*1.2),\n",
    "                Resample(sample_rate, sample_rate*1.3),\n",
    "                Resample(sample_rate, sample_rate*1.4)\n",
    "            ]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = random.choice(self.resamples)(x)\n",
    "        \n",
    "        x = self.stft(x)\n",
    "\n",
    "        if True:\n",
    "            dist = Uniform(1.-self.max_perc, 1+self.max_perc)\n",
    "            x = self.time_stretch(x, dist.sample().item())\n",
    "            x = self.com_norm(x)\n",
    "            x = self.fm(x, 0)\n",
    "            x = self.tm(x, 0)\n",
    "        else:\n",
    "            x = self.com_norm(x)\n",
    "        \n",
    "        x = self.mel_specgram.mel_scale(x)\n",
    "        x = self.AtoDB(x)\n",
    "        \n",
    "        size = torch.tensor(x.size())\n",
    "        \n",
    "        if size[2] > 280:\n",
    "            x = x[:,:,0:280]\n",
    "        else:\n",
    "            x = torch.cat([x, torch.cuda.FloatTensor(size[0], size[1], 280 - size[2]).fill_(0)], dim=2)\n",
    "        \n",
    "        return x.unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_concat_pool2d(x, sz=(1,1)):\n",
    "    out1 = F.adaptive_avg_pool2d(x, sz).view(x.size(0), -1)\n",
    "    out2 = F.adaptive_max_pool2d(x, sz).view(x.size(0), -1)\n",
    "    return torch.cat([out1, out2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_type, model_name, output_size, spectrogram_params, logmel_extractor_params, spec_augmenter_params):\n",
    "        super().__init__()\n",
    "        \n",
    "        \"\"\"self.spectrogram_extractor = Spectrogram(**spectrogram_params)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(**logmel_extractor_params)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(**spec_augmenter_params)\n",
    "        \n",
    "        self.bn0 = nn.BatchNorm2d(logmel_extractor_params['n_mels'])\"\"\"\n",
    "        self.mel = RondomStretchMelSpectrogram(sample_rate=SR, n_fft=2**11, top_db=80, max_perc=0.4)\n",
    "        \n",
    "        self.conv1 = ConvBlock(1,64)\n",
    "        self.conv2 = ConvBlock(64,128)\n",
    "        self.conv3 = ConvBlock(128,256)\n",
    "        self.conv4 = ConvBlock(256,512)\n",
    "        self.conv5 = ConvBlock(512,1024)\n",
    "        self.conv6 = ConvBlock(1024,2048,pool=False)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.BatchNorm1d(7936),\n",
    "            nn.Linear(7936, 2048),\n",
    "            nn.PReLU(),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.Linear(2048, 24),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"x = self.spectrogram_extractor(\n",
    "            input)  # (batch_size, 1, time_steps, freq_bins)\n",
    "        x = self.logmel_extractor(x)  # (batch_size, 1, time_steps, mel_bins)\n",
    "\n",
    "        frames_num = x.shape[2]\n",
    "\n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "\n",
    "        if self.training:\n",
    "            x = self.spec_augmenter(x)\n",
    "            \n",
    "        print(x.size())\"\"\"\n",
    "        \n",
    "        x = self.mel(input)\n",
    "        \n",
    "        x1 = self.conv1(x)\n",
    "        x1 = F.dropout(x1, p=0.2, training=self.training)\n",
    "        x2 = self.conv2(x1)\n",
    "        x2 = F.dropout(x2, p=0.2, training=self.training)\n",
    "        x3 = self.conv3(x2)\n",
    "        x3 = F.dropout(x3, p=0.2, training=self.training)\n",
    "        x4 = self.conv4(x3)\n",
    "        x4 = F.dropout(x4, p=0.2, training=self.training)\n",
    "        x5 = self.conv5(x4)\n",
    "        x5 = F.dropout(x5, p=0.2, training=self.training)\n",
    "        x6 = self.conv6(x5)\n",
    "        x6 = F.dropout(x6, p=0.2, training=self.training)\n",
    "        \n",
    "        \n",
    "        x = torch.cat([adaptive_concat_pool2d(x2), adaptive_concat_pool2d(x3),\n",
    "                       adaptive_concat_pool2d(x4),adaptive_concat_pool2d(x5),\n",
    "                       adaptive_concat_pool2d(x6)], 1)\n",
    "                \n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(epoch, fold, model, optim, criterion, file_path=\"../../model/\"):\n",
    "    if not TEST_NAME in os.listdir(file_path):\n",
    "        os.mkdir(file_path+TEST_NAME)\n",
    "    \n",
    "    \n",
    "    output_path = file_path + TEST_NAME + '/' + f\"{TEST_NAME}_{fold}_{epoch}.model\"\n",
    "    \n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.cpu().state_dict(),\n",
    "            'optimizer_state_dict': optim.state_dict(),\n",
    "            'criterion': criterion\n",
    "        },\n",
    "        output_path)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LRAP. Instance-level average\n",
    "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
    "def LRAP(preds, labels):\n",
    "    # Ranks of the predictions\n",
    "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
    "    # i, j corresponds to rank of prediction in row i\n",
    "    class_ranks = torch.zeros_like(ranked_classes)\n",
    "    for i in range(ranked_classes.size(0)):\n",
    "        for j in range(ranked_classes.size(1)):\n",
    "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
    "    # Mask out to only use the ranks of relevant GT labels\n",
    "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
    "    # All the GT ranks are in front now\n",
    "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
    "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
    "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
    "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
    "    scores = score_matrix * score_mask_matrix\n",
    "    score = (scores.sum(-1) / labels.sum(-1)).mean()\n",
    "    return score.item()\n",
    "\n",
    "# label-level average\n",
    "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
    "def LWLRAP(preds, labels):\n",
    "    # Ranks of the predictions\n",
    "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
    "    # i, j corresponds to rank of prediction in row i\n",
    "    class_ranks = torch.zeros_like(ranked_classes)\n",
    "    for i in range(ranked_classes.size(0)):\n",
    "        for j in range(ranked_classes.size(1)):\n",
    "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
    "    # Mask out to only use the ranks of relevant GT labels\n",
    "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
    "    # All the GT ranks are in front now\n",
    "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
    "    # Number of GT labels per instance\n",
    "    num_labels = labels.sum(-1)\n",
    "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
    "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
    "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
    "    scores = score_matrix * score_mask_matrix\n",
    "    score = scores.sum() / labels.sum()\n",
    "    return score.item()\n",
    "\n",
    "# Sample usage\n",
    "# y_true = torch.tensor(np.array([[1, 1, 0], [1, 0, 1], [0, 0, 1]]))\n",
    "# y_score = torch.tensor(np.random.randn(3, 3))\n",
    "# print(LRAP(y_score, y_true), LWLRAP(y_score, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NAME = 'baseline'\n",
    "\n",
    "n_splits = 5\n",
    "random_state = 1\n",
    "epochs = 35\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "spectrogram_params = {\n",
    "    'n_fft': 1024,\n",
    "    'hop_length': 320,\n",
    "    'win_length': 1024,\n",
    "    'window': 'hann',\n",
    "    'center': True,\n",
    "    'pad_mode': 'reflect',\n",
    "    'freeze_parameters': True\n",
    "}\n",
    "\n",
    "logmel_extractor_params = {\n",
    "    'sr': SR,\n",
    "    'n_fft': 1024,\n",
    "    'n_mels': 64,\n",
    "    'fmin': 50,\n",
    "    'fmax': 15000,\n",
    "    'ref' : 1.0,\n",
    "    'amin': 1e-10,\n",
    "    'top_db': None,\n",
    "    'freeze_parameters': True\n",
    "}\n",
    "\n",
    "spec_augmenter_params = {\n",
    "    'time_drop_width':  64,\n",
    "    'time_stripes_num': 2,\n",
    "    'freq_drop_width':  8,\n",
    "    'freq_stripes_num': 2\n",
    "}\n",
    "\n",
    "model_params = {\n",
    "    'model_type': 'res',\n",
    "    'model_name': 'resnet50',\n",
    "    'output_size': 24,\n",
    "    'spectrogram_params': spectrogram_params,\n",
    "    'logmel_extractor_params': logmel_extractor_params,\n",
    "    'spec_augmenter_params': spec_augmenter_params,\n",
    "}\n",
    "\n",
    "optim_params = {\n",
    "    'lr': 1e-3,\n",
    "    'weight_decay': 5e-5,\n",
    "    'betas': (0.9, 0.999)\n",
    "}\n",
    "\n",
    "scheduler_params = {\n",
    "    'mode': 'max',\n",
    "    'patience': 1,\n",
    "    'factor': 0.4,\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "data_params = {\n",
    "    'path': '../../data/train_tp_torch/',\n",
    "    'dataloder': {\n",
    "        'batch_size': 128,\n",
    "        'num_workers': 15,\n",
    "        'pin_memory': True,\n",
    "        'shuffle':False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- fold 0 ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuigahama/anaconda3/lib/python3.8/site-packages/torch/functional.py:515: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370172916/work/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore\n",
      "/home/yuigahama/anaconda3/lib/python3.8/site-packages/torch/functional.py:515: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370172916/work/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1| T | loss: 0.871 | score: 0.172 | V | loss: 9.41e+02 | score: 0.156 | time: 0:00:09\n",
      "epoch   2| T | loss: 0.707 | score: 0.196 | V | loss: 12.6 | score: 0.156 | time: 0:00:09\n",
      "epoch   3| T | loss: 0.653 | score: 0.195 | V | loss: 1.74 | score: 0.167 | time: 0:00:09\n",
      "epoch   4| T | loss: 0.609 | score: 0.211 | V | loss: 0.795 | score: 0.167 | time: 0:00:09\n",
      "epoch   5| T | loss: 0.551 | score: 0.244 | V | loss: 0.537 | score: 0.172 | time: 0:00:09\n",
      "epoch   6| T | loss: 0.476 | score: 0.256 | V | loss: 0.526 | score: 0.185 | time: 0:00:09\n",
      "epoch   7| T | loss: 0.39 | score: 0.229 | V | loss: 0.403 | score: 0.21 | time: 0:00:09\n",
      "epoch   8| T | loss: 0.307 | score: 0.238 | V | loss: 0.305 | score: 0.198 | time: 0:00:09\n",
      "epoch   9| T | loss: 0.244 | score: 0.247 | V | loss: 0.229 | score: 0.219 | time: 0:00:09\n",
      "epoch  10| T | loss: 0.204 | score: 0.248 | V | loss: 0.219 | score: 0.215 | time: 0:00:09\n",
      "epoch  11| T | loss: 0.182 | score: 0.263 | V | loss: 0.184 | score: 0.189 | time: 0:00:09\n",
      "epoch  12| T | loss: 0.171 | score: 0.303 | V | loss: 0.218 | score: 0.177 | time: 0:00:09\n",
      "epoch  13| T | loss: 0.167 | score: 0.313 | V | loss: 0.202 | score: 0.172 | time: 0:00:09\n",
      "epoch  14| T | loss: 0.164 | score: 0.335 | V | loss: 0.182 | score: 0.226 | time: 0:00:09\n",
      "epoch  15| T | loss: 0.163 | score: 0.349 | V | loss: 0.206 | score: 0.184 | time: 0:00:09\n",
      "epoch  16| T | loss: 0.163 | score: 0.327 | V | loss: 0.177 | score: 0.222 | time: 0:00:09\n",
      "epoch  17| T | loss: 0.161 | score: 0.361 | V | loss: 0.207 | score: 0.178 | time: 0:00:09\n",
      "epoch  18| T | loss: 0.16 | score: 0.358 | V | loss: 0.241 | score: 0.224 | time: 0:00:09\n",
      "epoch  19| T | loss: 0.161 | score: 0.35 | V | loss: 0.206 | score: 0.201 | time: 0:00:09\n",
      "epoch  20| T | loss: 0.161 | score: 0.355 | V | loss: 0.194 | score: 0.193 | time: 0:00:09\n",
      "epoch  21| T | loss: 0.161 | score: 0.354 | V | loss: 0.179 | score: 0.188 | time: 0:00:09\n",
      "epoch  22| T | loss: 0.159 | score: 0.368 | V | loss: 0.182 | score: 0.221 | time: 0:00:09\n",
      "epoch  23| T | loss: 0.16 | score: 0.36 | V | loss: 0.22 | score: 0.181 | time: 0:00:09\n",
      "epoch  24| T | loss: 0.16 | score: 0.365 | V | loss: 0.177 | score: 0.203 | time: 0:00:09\n",
      "epoch  25| T | loss: 0.16 | score: 0.37 | V | loss: 0.289 | score: 0.175 | time: 0:00:09\n",
      "epoch  26| T | loss: 0.16 | score: 0.354 | V | loss: 0.18 | score: 0.222 | time: 0:00:09\n",
      "epoch  27| T | loss: 0.159 | score: 0.375 | V | loss: 0.264 | score: 0.179 | time: 0:00:09\n",
      "epoch  28| T | loss: 0.16 | score: 0.356 | V | loss: 0.179 | score: 0.214 | time: 0:00:09\n",
      "epoch  29| T | loss: 0.16 | score: 0.354 | V | loss: 0.205 | score: 0.192 | time: 0:00:09\n",
      "epoch  30| T | loss: 0.16 | score: 0.37 | V | loss: 0.173 | score: 0.204 | time: 0:00:09\n",
      "epoch  31| T | loss: 0.16 | score: 0.371 | V | loss: 0.176 | score: 0.223 | time: 0:00:09\n",
      "epoch  32| T | loss: 0.16 | score: 0.362 | V | loss: 0.207 | score: 0.195 | time: 0:00:09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/yuigahama/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-c776961bcd31>\", line 39, in <module>\n",
      "    train_loss += loss.item()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yuigahama/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yuigahama/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/yuigahama/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/yuigahama/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/yuigahama/anaconda3/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/yuigahama/anaconda3/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/yuigahama/anaconda3/lib/python3.8/inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/yuigahama/anaconda3/lib/python3.8/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-c776961bcd31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mtrain_score\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2047\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2048\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1437\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1194\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "for fold_id, (train_index, val_index) in enumerate(skf.split(train_tp, train_tp.species_id)):\n",
    "    print(f'---------- fold {fold_id} ----------')\n",
    "    \n",
    "    model = BaseModel(**model_params).to(device)\n",
    "    optim = Adam(model.parameters(), **optim_params)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer=optim, **scheduler_params)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    train_dataset = RfcxDataSet(train_tp.iloc[train_index], data_params['path'])\n",
    "    val_dataset = RfcxDataSet(train_tp.iloc[val_index], data_params['path'])\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, **data_params['dataloder'])\n",
    "    val_dataloader = DataLoader(val_dataset, **data_params['dataloder'])\n",
    "    \n",
    "    for epoch in range(1, epochs):\n",
    "        es = 5\n",
    "        \n",
    "        start_time = time.time()\n",
    "        bast_score = 0\n",
    "        \n",
    "        # train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_score = 0\n",
    "        \n",
    "        for data in train_dataloader:\n",
    "            image = data[0].to(device)\n",
    "            label = data[1].to(device)\n",
    "            \n",
    "            pred = model(image)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            loss = criterion(pred, label)\n",
    "            score = LWLRAP(pred.cpu(), label.cpu())\n",
    "            \n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_score += score\n",
    "            \n",
    "        train_loss  /= len(train_dataloader)\n",
    "        train_score /= len(train_dataloader)\n",
    "        \n",
    "        # val\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_score = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for val_data in val_dataloader:\n",
    "                image = val_data[0].to(device)\n",
    "                label = val_data[1].to(device)\n",
    "\n",
    "                pred = model(image)\n",
    "                loss = criterion(pred, label)\n",
    "                score = LWLRAP(pred.cpu(), label.cpu())\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_score += score\n",
    "\n",
    "                \n",
    "        val_loss  /= len(val_dataloader)\n",
    "        val_score /= len(val_dataloader)\n",
    "        \n",
    "        duration = str(datetime.timedelta(seconds=time.time() - start_time))[:7]\n",
    "        print(f'epoch {epoch:3}| T | loss: {train_loss:.3} | score: {train_score:.3} | V | loss: {val_loss:.3} | score: {val_score:.3} | time: {duration}')\n",
    "\n",
    "        if bast_score < val_score:\n",
    "            bast_score = val_score\n",
    "            save(epoch, fold_id, model, optim, criterion)\n",
    "        else:\n",
    "            es -= 1\n",
    "            \n",
    "            if es == 0:\n",
    "                break\n",
    "        scheduler.step(val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
