{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuigahama/anaconda3/lib/python3.8/site-packages/torchaudio/backend/utils.py:53: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, AdamW, lr_scheduler\n",
    "from torch.distributions import Uniform\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchvision.models import resnet34, resnet50\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from libs import transform as tr\n",
    "from libs import spectrogram as spec\n",
    "from libs import criterion as cr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = False  # type: ignore\n",
    "set_seed(53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tp = pd.read_csv('../../data/train_tp.csv')\n",
    "train_fp = pd.read_csv('../../data/train_fp.csv')\n",
    "submission = pd.read_csv('../../data/sample_submission.csv')\n",
    "\n",
    "pred_target = list(submission.columns)[1:]\n",
    "\n",
    "SR = 48000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_melspec(X: np.ndarray):\n",
    "    eps = 1e-6\n",
    "    mean = X.mean()\n",
    "    X = X - mean\n",
    "    std = X.std()\n",
    "    Xstd = X / (std + eps)\n",
    "    norm_min, norm_max = Xstd.min(), Xstd.max()\n",
    "    if (norm_max - norm_min) > eps:\n",
    "        V = Xstd\n",
    "        V[V < norm_min] = norm_min\n",
    "        V[V > norm_max] = norm_max\n",
    "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        # Just zero\n",
    "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
    "    return V\n",
    "\n",
    "def save(fold, model, optim, criterion, file_path=\"../../model/\"):\n",
    "    if not TEST_NAME in os.listdir(file_path):\n",
    "        os.mkdir(file_path+TEST_NAME)\n",
    "    \n",
    "    \n",
    "    output_path = file_path + TEST_NAME + '/' + f\"{TEST_NAME}_{fold}.model\"\n",
    "    \n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.cpu().state_dict(),\n",
    "            'optimizer_state_dict': optim.state_dict(),\n",
    "            'criterion': criterion\n",
    "        },\n",
    "        output_path)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RfcxDataSet(Dataset):\n",
    "    def __init__(self,\n",
    "                 tp:pd.DataFrame,\n",
    "                 train: bool,\n",
    "                 data_path:str,\n",
    "                 pcen_parameters:dict,\n",
    "                 pre_calc=True,\n",
    "                 n_mels=128\n",
    "    ):\n",
    "        self.tp = tp\n",
    "        self.path = data_path\n",
    "        self.img_size = 256\n",
    "        self.train = train\n",
    "        self.n_mels = n_mels\n",
    "        self.pre_calc = pre_calc\n",
    "        \n",
    "        self.transform = tr.Compose([\n",
    "            tr.OneOf([\n",
    "                tr.GaussianNoiseSNR(min_snr=10),\n",
    "                tr.PinkNoiseSNR(min_snr=10)\n",
    "            ]),\n",
    "            tr.PitchShift(max_steps=2, sr=SR),\n",
    "            #tr.TimeStretch(),\n",
    "            #tr.TimeShift(sr=sr),\n",
    "            tr.VolumeControl(mode=\"sine\")\n",
    "        ])\n",
    "        \n",
    "        self.pcen_parameters = pcen_parameters\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tp)\n",
    "    \n",
    "    def load(self, record_path):\n",
    "        y, orig_sr = sf.read(record_path)\n",
    "        \n",
    "        if orig_sr != SR:\n",
    "            y = librosa.resample(y, orig_sr=orig_sr, target_sr=SR, res_type=\"kaiser_best\")\n",
    "        return y\n",
    "    \n",
    "    def get_random_duration(self, duration=10):\n",
    "        start_sec = random.randint(0, 60-duration)\n",
    "        end_sec = start_sec + 10\n",
    "            \n",
    "        return start_sec, end_sec\n",
    "    \n",
    "    def get_duration(self, t_min, t_max, duration=10):\n",
    "        annotated_duration = t_max - t_min\n",
    "        \n",
    "        if annotated_duration > duration:\n",
    "            limit_sec = t_max - duration\n",
    "            start_sec = random.randint(t_min, limit_sec)\n",
    "            end_sec = start_sec + duration\n",
    "\n",
    "        else:\n",
    "            res_time = duration - annotated_duration\n",
    "            front_limit = res_time if res_time < t_min else t_min\n",
    "            \n",
    "            front_time = random.randint(0, front_limit)\n",
    "            \n",
    "            back_limit = 60 - t_max\n",
    "            \n",
    "            tmp_time = res_time - front_time\n",
    "            back_time = tmp_time if tmp_time < back_limit else back_limit\n",
    "            \n",
    "            if not tmp_time < back_limit:\n",
    "                front_time += tmp_time - back_limit\n",
    "            \n",
    "            start_sec = t_min - front_time\n",
    "            end_sec = t_max + back_time\n",
    "            \n",
    "        return start_sec, end_sec\n",
    "    \n",
    "    def create_mel(self, y):\n",
    "        y = self.transform(y)\n",
    "        \n",
    "        melspec = librosa.feature.melspectrogram(\n",
    "            y,\n",
    "            sr=SR,\n",
    "            fmin=0,\n",
    "            fmax=15000,\n",
    "            n_mels=128\n",
    "        )\n",
    "\n",
    "        pcen = librosa.pcen(melspec, sr=SR, **self.pcen_parameters)\n",
    "        clean_mel = librosa.power_to_db(melspec ** 1.5)\n",
    "        melspec = librosa.power_to_db(melspec)\n",
    "\n",
    "        norm_melspec = normalize_melspec(melspec)\n",
    "        norm_pcen = normalize_melspec(pcen)\n",
    "        norm_clean_mel = normalize_melspec(clean_mel)\n",
    "\n",
    "        image = np.stack([norm_melspec, norm_pcen, norm_clean_mel], axis=-1)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        sample = self.tp.iloc[idx, :]\n",
    "        recording_id = sample['recording_id']\n",
    "        t_min = int(round(sample['t_min']))\n",
    "        t_max = int(round(sample['t_max']))\n",
    "        \n",
    "        start_sec, end_sec = self.get_duration(t_min, t_max, 10)\n",
    "        \n",
    "        if self.pre_calc:\n",
    "            image = torch.load(self.path + recording_id + '.tensor')\n",
    "            time_rate = int(image.shape[1] / 60)\n",
    "                \n",
    "            start = int(start_sec * time_rate)\n",
    "            end = int(end_sec * time_rate)\n",
    "\n",
    "            image = image[:, start:end, :]\n",
    "            \n",
    "        else:\n",
    "            record_path = self.path + recording_id + '.flac'\n",
    "            y = self.load(record_path)\n",
    "            y =  y[start_sec*SR:end_sec*SR]\n",
    "            image = self.create_mel(y)\n",
    "        \n",
    "        height, width, _ = image.shape\n",
    "        image = cv2.resize(image, (self.img_size * 2, self.img_size))\n",
    "        image = np.moveaxis(image, 2, 0)\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "        \n",
    "        species_id = sample['species_id']\n",
    "        target = torch.zeros([24], dtype=torch.float32)\n",
    "        target[species_id] = 1\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRfcx(Dataset):\n",
    "    def __init__(self, df, path, duration=10, train=True):\n",
    "        self.df = df\n",
    "        self.path = path\n",
    "        self.train = train\n",
    "        self.img_size = 256\n",
    "        self.duration = duration\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, idx: int):\n",
    "        sample = self.df.iloc[idx, :]\n",
    "        recording_id = sample['recording_id']\n",
    "        data = torch.load(\n",
    "            self.path + recording_id + '.tensor'\n",
    "        )\n",
    "        \n",
    "        image_ = data\n",
    "            \n",
    "        time_rate = int(image_.shape[1] / 60)\n",
    "        \n",
    "        images = []\n",
    "        \n",
    "        for s in range(0,60,self.duration):\n",
    "            start_sec = s\n",
    "            end_sec   = s + self.duration\n",
    "\n",
    "            start = int(start_sec * time_rate)\n",
    "            end = int(end_sec * time_rate)\n",
    "        \n",
    "            image = image_[:, start:end, :]\n",
    "            \n",
    "            height, width, _ = image.shape\n",
    "            image = cv2.resize(image, (self.img_size * 2, self.img_size))\n",
    "            image = np.moveaxis(image, 2, 0)\n",
    "            image = (image / 255.0).astype(np.float32)\n",
    "            \n",
    "            images.append(image)\n",
    "        \n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "\n",
    "\n",
    "def init_weights(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find(\"Conv2d\") != -1:\n",
    "        nn.init.xavier_uniform_(model.weight, gain=np.sqrt(2))\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        model.weight.data.normal_(1.0, 0.02)\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"GRU\") != -1:\n",
    "        for weight in model.parameters():\n",
    "            if len(weight.size()) > 1:\n",
    "                nn.init.orghogonal_(weight.data)\n",
    "    elif classname.find(\"Linear\") != -1:\n",
    "        model.weight.data.normal_(0, 0.01)\n",
    "        model.bias.data.zero_()\n",
    "\n",
    "\n",
    "def do_mixup(x: torch.Tensor, mixup_lambda: torch.Tensor):\n",
    "    \"\"\"Mixup x of even indexes (0, 2, 4, ...) with x of odd indexes\n",
    "    (1, 3, 5, ...).\n",
    "    Args:\n",
    "      x: (batch_size * 2, ...)\n",
    "      mixup_lambda: (batch_size * 2,)\n",
    "    Returns:\n",
    "      out: (batch_size, ...)\n",
    "    \"\"\"\n",
    "    out = (x[0::2].transpose(0, -1) * mixup_lambda[0::2] +\n",
    "           x[1::2].transpose(0, -1) * mixup_lambda[1::2]).transpose(0, -1)\n",
    "    return out\n",
    "\n",
    "\n",
    "class Mixup(object):\n",
    "    def __init__(self, mixup_alpha, random_seed=1234):\n",
    "        \"\"\"Mixup coefficient generator.\n",
    "        \"\"\"\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "        self.random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    def get_lambda(self, batch_size):\n",
    "        \"\"\"Get mixup random coefficients.\n",
    "        Args:\n",
    "          batch_size: int\n",
    "        Returns:\n",
    "          mixup_lambdas: (batch_size,)\n",
    "        \"\"\"\n",
    "        mixup_lambdas = []\n",
    "        for n in range(0, batch_size, 2):\n",
    "            lam = self.random_state.beta(self.mixup_alpha, self.mixup_alpha, 1)[0]\n",
    "            mixup_lambdas.append(lam)\n",
    "            mixup_lambdas.append(1. - lam)\n",
    "\n",
    "        return torch.from_numpy(np.array(mixup_lambdas, dtype=np.float32))\n",
    "\n",
    "\n",
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "\n",
    "def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n",
    "    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n",
    "    is the same as the value of the last frame.\n",
    "    Args:\n",
    "      framewise_output: (batch_size, frames_num, classes_num)\n",
    "      frames_num: int, number of frames to pad\n",
    "    Outputs:\n",
    "      output: (batch_size, frames_num, classes_num)\n",
    "    \"\"\"\n",
    "    pad = framewise_output[:, -1:, :].repeat(\n",
    "        1, frames_num - framewise_output.shape[1], 1)\n",
    "    \"\"\"tensor for padding\"\"\"\n",
    "\n",
    "    output = torch.cat((framewise_output, pad), dim=1)\n",
    "    \"\"\"(batch_size, frames_num, classes_num)\"\"\"\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\",\n",
    "                 temperature=1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.temperature = temperature\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.bn_att = nn.BatchNorm1d(out_features)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "        init_bn(self.bn_att)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.clamp(self.att(x), -10, 10), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class AttBlockV2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetSED(nn.Module):\n",
    "    def __init__(self, base_model_name: str, pretrained=False,\n",
    "                 num_classes=24):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.interpolate_ratio = 30  # Downsampled ratio\n",
    "        self.mixup_alpha = 0.2\n",
    "        self.random_state = np.random.RandomState(123)\n",
    "        \n",
    "        if pretrained:\n",
    "            self.base_model = EfficientNet.from_pretrained(base_model_name)\n",
    "        else:\n",
    "            self.base_model = EfficientNet.from_name(base_model_name)\n",
    "\n",
    "        in_features = self.base_model._fc.in_features\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n",
    "        self.att_block = AttBlockV2(in_features, num_classes, activation=\"sigmoid\")\n",
    "\n",
    "        self.init_weight()\n",
    "        \n",
    "    def mixup(self, x):\n",
    "        lam = self.random_state.beta(self.mixup_alpha, self.mixup_alpha, 1)[0]\n",
    "        index = list(range(x.size(0)))\n",
    "        random.shuffle(index)\n",
    "        out = (x * lam + x[index].squeeze() * (1-lam))\n",
    "        \n",
    "        return out, {'lam': lam, 'index': index}\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_layer(self.fc1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        frames_num = input.size(3)\n",
    "        \n",
    "        if self.training:\n",
    "            input, mix_info = self.mixup(input)\n",
    "        else:\n",
    "            mix_info = None\n",
    "                \n",
    "        # (batch_size, channels, freq, frames)\n",
    "        x = self.base_model.extract_features(input)\n",
    "\n",
    "        # (batch_size, channels, frames)\n",
    "        x = torch.mean(x, dim=2)\n",
    "\n",
    "        # channel smoothing\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n",
    "        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        # Get framewise output\n",
    "        framewise_output = interpolate(segmentwise_output,\n",
    "                                       self.interpolate_ratio)\n",
    "        framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
    "\n",
    "        framewise_logit = interpolate(segmentwise_logit, self.interpolate_ratio)\n",
    "        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n",
    "\n",
    "        output_dict = {\n",
    "            \"framewise_output\": framewise_output,\n",
    "            \"segmentwise_output\": segmentwise_output,\n",
    "            \"logit\": logit,\n",
    "            \"framewise_logit\": framewise_logit,\n",
    "            \"clipwise_output\": clipwise_output\n",
    "        }\n",
    "\n",
    "        return output_dict, mix_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LRAP. Instance-level average\n",
    "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
    "def LRAP(preds, labels):\n",
    "    # Ranks of the predictions\n",
    "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
    "    # i, j corresponds to rank of prediction in row i\n",
    "    class_ranks = torch.zeros_like(ranked_classes)\n",
    "    for i in range(ranked_classes.size(0)):\n",
    "        for j in range(ranked_classes.size(1)):\n",
    "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
    "    # Mask out to only use the ranks of relevant GT labels\n",
    "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
    "    # All the GT ranks are in front now\n",
    "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
    "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
    "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
    "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
    "    scores = score_matrix * score_mask_matrix\n",
    "    score = (scores.sum(-1) / labels.sum(-1)).mean()\n",
    "    return score.item()\n",
    "\n",
    "# label-level average\n",
    "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
    "def LWLRAP(preds, labels):\n",
    "    # Ranks of the predictions\n",
    "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
    "    # i, j corresponds to rank of prediction in row i\n",
    "    class_ranks = torch.zeros_like(ranked_classes)\n",
    "    for i in range(ranked_classes.size(0)):\n",
    "        for j in range(ranked_classes.size(1)):\n",
    "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
    "    # Mask out to only use the ranks of relevant GT labels\n",
    "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
    "    # All the GT ranks are in front now\n",
    "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
    "    # Number of GT labels per instance\n",
    "    num_labels = labels.sum(-1)\n",
    "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
    "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
    "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
    "    scores = score_matrix * score_mask_matrix\n",
    "    score = scores.sum() / labels.sum()\n",
    "    return score.item()\n",
    "\n",
    "def mixup_socre(cor, x, y, mix_info):\n",
    "    return cor(x, y) * mix_info['lam'] + cor(x, y[mix_info['index']].squeeze()) * (1-mix_info['lam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NAME = 'baseline-pic-res'\n",
    "\n",
    "n_splits = 5\n",
    "random_state = 1\n",
    "epochs = 75\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_params = {\n",
    "    'base_model_name': 'efficientnet-b0',\n",
    "    'pretrained': True,\n",
    "    'num_classes': 24,\n",
    "}\n",
    "\n",
    "optim_params = {\n",
    "    'lr': 1e-3,\n",
    "    'weight_decay': 5e-5,\n",
    "    'betas': (0.9, 0.999)\n",
    "}\n",
    "\n",
    "scheduler_params = {\n",
    "    'mode': 'max',\n",
    "    'patience': 1,\n",
    "    'factor': 0.6,\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "pcen_parameters = {\n",
    "    'gain': 0.98,\n",
    "    'bias': 2,\n",
    "    'power': 0.5,\n",
    "    'time_constant': 0.4,\n",
    "    'eps': 0.000001,\n",
    "}\n",
    "\n",
    "train_params = {\n",
    "    'pcen_parameters': pcen_parameters,\n",
    "    'pre_calc': False,\n",
    "    'train': True,\n",
    "    'data_path': '/home/yuigahama/kaggle/rfcx/data/train/'  \n",
    "}\n",
    "\n",
    "val_params = {\n",
    "    'train': True,\n",
    "    'pcen_parameters': pcen_parameters,\n",
    "    'data_path': '/home/yuigahama/kaggle/rfcx/data/train_wo_fp/'\n",
    "}\n",
    "\n",
    "test_data_params = {\n",
    "    'train': False,\n",
    "    'path': '/home/yuigahama/kaggle/rfcx/data/test_wo_fp/',\n",
    "    'duration': 20\n",
    "}\n",
    "\n",
    "dataloder_params = {\n",
    "    'batch_size': 16,\n",
    "    'num_workers': 15,\n",
    "    'pin_memory': False,\n",
    "}\n",
    "\n",
    "test_dataloder_params = {\n",
    "    'batch_size': 32,\n",
    "    'num_workers': 15,\n",
    "    'pin_memory': False,\n",
    "    'shuffle':False\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "tta = np.zeros((len(submission), 24))\n",
    "cv_score = 0\n",
    "\n",
    "for fold_id, (train_index, val_index) in enumerate(skf.split(train_tp, train_tp.species_id)):\n",
    "    print(f'---------- fold {fold_id} ----------')\n",
    "    \n",
    "    model = EfficientNetSED(**model_params).to(device)\n",
    "    optim = Adam(model.parameters(), **optim_params)\n",
    "    #scheduler = lr_scheduler.ReduceLROnPlateau(optimizer=optim, **scheduler_params)\n",
    "    scheduler = lr_scheduler.CosineAnnealingLR(optimizer=optim, T_max=epochs)\n",
    "    \n",
    "    pos_weights = torch.ones(24)\n",
    "    pos_weights = pos_weights * 24\n",
    "    criterion = cr.ImprovedFocalLoss(weights=[1, 0.5])\n",
    "    \n",
    "    train_dataset = RfcxDataSet(train_tp.iloc[train_index], **train_params)\n",
    "    val_dataset   = RfcxDataSet(train_tp.iloc[val_index], **val_params)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, shuffle=True, **dataloder_params)\n",
    "    val_dataloader = DataLoader(val_dataset, shuffle=False, **dataloder_params)\n",
    "    \n",
    "    es = 20\n",
    "    for epoch in range(1, epochs):\n",
    "        if es <= 0:\n",
    "            break\n",
    "        \n",
    "        start_time = time.time()\n",
    "        bast_score = 0\n",
    "        \n",
    "        # train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_score = 0\n",
    "        train_corr = 0\n",
    "        \n",
    "        for data in train_dataloader:\n",
    "            image = data[0].float().to(device)\n",
    "            label = data[1]\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            output, mix_info = model(image)\n",
    "            \n",
    "            output = {k:v.cpu() for k,v in output.items()}\n",
    "            \n",
    "            loss = mixup_socre(criterion, output, label, mix_info)            \n",
    "            #loss = criterion(output, label)\n",
    "            pred_labels = output[\"framewise_output\"].max(1)[0]\n",
    "            score = mixup_socre(LWLRAP, pred_labels, label, mix_info)\n",
    "            \n",
    "            #score = LWLRAP(pred_labels, label)\n",
    "                        \n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            vals, answers = torch.max(pred_labels, 1)\n",
    "            vals, targets = torch.max(label, 1)\n",
    "            vals, targets2 = torch.max(label[mix_info['index']], 1)\n",
    "            \n",
    "            corrects = 0\n",
    "            for i in range(0, len(answers)):\n",
    "                if answers[i] == targets[i]:\n",
    "                    corrects = corrects + 1\n",
    "                if answers[i] == targets2[i]:\n",
    "                    corrects = corrects + 1\n",
    "                \n",
    "            corrects = 1 if corrects > 0 else 0\n",
    "                    \n",
    "            \n",
    "            train_corr += corrects\n",
    "            train_loss += loss.item()\n",
    "            train_score += score\n",
    "            \n",
    "        train_loss  /= len(train_dataloader)\n",
    "        train_score /= len(train_dataloader)\n",
    "        \n",
    "        # val\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_score = 0\n",
    "        val_corr = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_dataloader:\n",
    "                image = val_data[0].float().to(device)\n",
    "                label = val_data[1]\n",
    "\n",
    "                output, mix_info = model(image)\n",
    "                output = {k:v.cpu() for k,v in output.items()}\n",
    "                \n",
    "                pred_labels = output[\"framewise_output\"].max(1)[0]\n",
    "                vals, answers = torch.max(pred_labels, 1)\n",
    "                vals, targets = torch.max(label, 1)\n",
    "                \n",
    "                corrects = 0\n",
    "                for i in range(0, len(answers)):\n",
    "                    if answers[i] == targets[i]:\n",
    "                        corrects = corrects + 1\n",
    "\n",
    "                val_corr += corrects\n",
    "                val_loss += criterion(output, label)\n",
    "                val_score += LWLRAP(pred_labels, label)\n",
    "                \n",
    "        val_loss  /= len(val_dataloader)\n",
    "        val_score /= len(val_dataloader)\n",
    "        \n",
    "        duration = str(datetime.timedelta(seconds=time.time() - start_time))[:7]\n",
    "        print(f'epoch {epoch:3}| T | L: {train_loss:.3} | S: {train_score:.3} | C: {train_corr}/{len(train_dataset)} | \\\n",
    "            V | L: {val_loss:.3} | S: {val_score:.3} | C: {val_corr}/{len(val_dataset)} | time: {duration} | es: {es}')\n",
    "\n",
    "        if bast_score < val_score:\n",
    "            bast_score = val_score\n",
    "            bast_path = save(fold_id, model, optim, criterion)\n",
    "        else:\n",
    "            es -= 1\n",
    "        \n",
    "        if es <= 0:\n",
    "            break\n",
    "        \n",
    "        scheduler.step(val_score)\n",
    "        \n",
    "    del model, train_dataset, val_dataset, train_dataloader, val_dataloader, optim\n",
    "    gc.collect()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EfficientNetSED(**model_params).to(device)\n",
    "params = torch.load(f'/home/yuigahama/kaggle/rfcx/model/baseline-pic-res/baseline-pic-res_1.model')\n",
    "model.load_state_dict(params['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SimpleRfcx(submission, **test_data_params)\n",
    "test_dataloader = DataLoader(test_dataset, **test_dataloder_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:12,  5.19it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    start = 0\n",
    "    oof = np.zeros((len(submission), 24))\n",
    "\n",
    "    for i, test_data in tqdm(enumerate(test_dataloader)):\n",
    "        target_size = test_data[0].size(0)\n",
    "        tmp = np.zeros((target_size, 24))\n",
    "        clip_num = len(test_data)\n",
    "\n",
    "        for d in test_data:\n",
    "            image = d.float().to(device)\n",
    "            end = start + target_size\n",
    "\n",
    "            output, mix_info = model(image)\n",
    "\n",
    "            pred_labels = output[\"framewise_output\"].max(1)[0].detach().cpu().numpy()\n",
    "            tmp += pred_labels / clip_num\n",
    "\n",
    "        oof[start:end, :] = tmp\n",
    "        start = end\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s0</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>...</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>s22</th>\n",
       "      <th>s23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.664278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.532366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.724852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.622595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.569574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.831496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.699445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1992 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            s0   s1   s2        s3   s4        s5   s6   s7   s8   s9  ...  \\\n",
       "0     0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  ...   \n",
       "1     0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  ...   \n",
       "2     0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  ...   \n",
       "3     0.532366  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  ...   \n",
       "4     0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  ...   \n",
       "...        ...  ...  ...       ...  ...       ...  ...  ...  ...  ...  ...   \n",
       "1987  0.000000  0.0  0.0  0.000000  0.0  0.622595  0.0  0.0  0.0  0.0  ...   \n",
       "1988  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  ...   \n",
       "1989  0.000000  0.0  0.0  0.831496  0.0  0.000000  0.0  0.0  0.0  0.0  ...   \n",
       "1990  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  ...   \n",
       "1991  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "           s14       s15       s16  s17  s18       s19  s20  s21  s22  s23  \n",
       "0     0.000000  0.000000  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  \n",
       "1     0.000000  0.000000  0.664278  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  \n",
       "2     0.000000  0.000000  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  \n",
       "3     0.000000  0.000000  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  \n",
       "4     0.724852  0.000000  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  \n",
       "...        ...       ...       ...  ...  ...       ...  ...  ...  ...  ...  \n",
       "1987  0.000000  0.569574  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  \n",
       "1988  0.000000  0.000000  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  \n",
       "1989  0.000000  0.000000  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  \n",
       "1990  0.000000  0.000000  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  \n",
       "1991  0.000000  0.000000  0.000000  0.0  0.0  0.699445  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[1992 rows x 24 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sub = pd.DataFrame(oof, columns=pred_target)\n",
    "pred_sub[pred_sub < 0.5] = 0\n",
    "pred_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([submission['recording_id'], pred_sub], axis=1).to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
