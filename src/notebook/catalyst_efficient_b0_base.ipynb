{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuigahama/anaconda3/lib/python3.8/site-packages/torchaudio/backend/utils.py:53: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, List\n",
    "from glob import glob\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "import logging\n",
    "import yaml\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, AdamW, lr_scheduler\n",
    "from torch.distributions import Uniform\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchvision.models import resnet34, resnet50\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from libs import transform as tr\n",
    "from libs import spectrogram as spec\n",
    "from libs import criterion as cr\n",
    "from libs import wormup as wu\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from catalyst.dl import SupervisedRunner, State, CallbackOrder, Callback, CheckpointCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../settings/catalyst_efficient_b0_base.yaml') as f:\n",
    "    settings = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = False  # type: ignore\n",
    "    \n",
    "def get_logger(out_file=None):\n",
    "    logger = logging.getLogger()\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    logger.handlers = []\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(formatter)\n",
    "    handler.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    if out_file is not None:\n",
    "        fh = logging.FileHandler(out_file)\n",
    "        fh.setFormatter(formatter)\n",
    "        fh.setLevel(logging.INFO)\n",
    "        logger.addHandler(fh)\n",
    "    logger.info(\"logger set up\")\n",
    "    return logger\n",
    "    \n",
    "    \n",
    "@contextmanager\n",
    "def timer(name: str, logger: Optional[logging.Logger] = None):\n",
    "    t0 = time.time()\n",
    "    msg = f\"[{name}] start\"\n",
    "    if logger is None:\n",
    "        print(msg)\n",
    "    else:\n",
    "        logger.info(msg)\n",
    "    yield\n",
    "\n",
    "    msg = f\"[{name}] done in {time.time() - t0:.2f} s\"\n",
    "    if logger is None:\n",
    "        print(msg)\n",
    "    else:\n",
    "        logger.info(msg)\n",
    "    \n",
    "    \n",
    "set_seed(1213)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_melspec(X: np.ndarray):\n",
    "    eps = 1e-6\n",
    "    mean = X.mean()\n",
    "    X = X - mean\n",
    "    std = X.std()\n",
    "    Xstd = X / (std + eps)\n",
    "    norm_min, norm_max = Xstd.min(), Xstd.max()\n",
    "    if (norm_max - norm_min) > eps:\n",
    "        V = Xstd\n",
    "        V[V < norm_min] = norm_min\n",
    "        V[V > norm_max] = norm_max\n",
    "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        # Just zero\n",
    "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
    "    return V\n",
    "\n",
    "def save(fold, model, optim, criterion, file_path=\"../../model/\"):\n",
    "    if not TEST_NAME in os.listdir(file_path):\n",
    "        os.mkdir(file_path+TEST_NAME)\n",
    "    \n",
    "    \n",
    "    output_path = file_path + TEST_NAME + '/' + f\"{TEST_NAME}_{fold}.model\"\n",
    "    \n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.cpu().state_dict(),\n",
    "            'optimizer_state_dict': optim.state_dict(),\n",
    "            'criterion': criterion\n",
    "        },\n",
    "        output_path)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RfcxDataSet(Dataset):\n",
    "    def __init__(self,\n",
    "                 tp:pd.DataFrame,\n",
    "                 train: bool,\n",
    "                 data_path:str,\n",
    "                 pre_calc=True,\n",
    "                 n_mels=128\n",
    "    ):\n",
    "        self.tp = tp\n",
    "        self.path = data_path\n",
    "        self.img_size = 256\n",
    "        self.train = train\n",
    "        self.n_mels = n_mels\n",
    "        self.pre_calc = pre_calc\n",
    "        \n",
    "        self.transform = tr.Compose([\n",
    "            tr.OneOf([\n",
    "                tr.GaussianNoiseSNR(min_snr=10),\n",
    "                tr.PinkNoiseSNR(min_snr=10)\n",
    "            ]),\n",
    "            tr.PitchShift(max_steps=2, sr=SR),\n",
    "            #tr.TimeStretch(),\n",
    "            #tr.TimeShift(sr=sr),\n",
    "            tr.VolumeControl(mode=\"sine\")\n",
    "        ])\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.tp)\n",
    "    \n",
    "    def load(self, record_path):\n",
    "        y, orig_sr = sf.read(record_path)\n",
    "        \n",
    "        if orig_sr != SR:\n",
    "            y = librosa.resample(y, orig_sr=orig_sr, target_sr=SR, res_type=\"kaiser_best\")\n",
    "        return y\n",
    "    \n",
    "    def get_random_duration(self, duration=10):\n",
    "        start_sec = random.randint(0, 60-duration)\n",
    "        end_sec = start_sec + 10\n",
    "            \n",
    "        return start_sec, end_sec\n",
    "    \n",
    "    def get_duration(self, t_min, t_max, duration=10):\n",
    "        annotated_duration = t_max - t_min\n",
    "        \n",
    "        if annotated_duration > duration:\n",
    "            limit_sec = t_max - duration\n",
    "            start_sec = random.randint(t_min, limit_sec)\n",
    "            end_sec = start_sec + duration\n",
    "\n",
    "        else:\n",
    "            res_time = duration - annotated_duration\n",
    "            front_limit = res_time if res_time < t_min else t_min\n",
    "            \n",
    "            front_time = random.randint(0, front_limit)\n",
    "            \n",
    "            back_limit = 60 - t_max\n",
    "            \n",
    "            tmp_time = res_time - front_time\n",
    "            back_time = tmp_time if tmp_time < back_limit else back_limit\n",
    "            \n",
    "            if not tmp_time < back_limit:\n",
    "                front_time += tmp_time - back_limit\n",
    "            \n",
    "            start_sec = t_min - front_time\n",
    "            end_sec = t_max + back_time\n",
    "            \n",
    "        return start_sec, end_sec\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        sample = self.tp.iloc[idx, :]\n",
    "        recording_id = sample['recording_id']\n",
    "        t_min = int(round(sample['t_min']))\n",
    "        t_max = int(round(sample['t_max']))\n",
    "        \n",
    "        start_sec, end_sec = self.get_duration(t_min, t_max, 10)\n",
    "            \n",
    "        record_path = self.path + recording_id + '.flac'\n",
    "        y = self.load(record_path)\n",
    "        y =  y[start_sec*SR:end_sec*SR]\n",
    "        \n",
    "        if self.train:\n",
    "            y = self.transform(y)\n",
    "                    \n",
    "        species_id = sample['species_id']\n",
    "        target = torch.zeros([24], dtype=torch.float32)\n",
    "        target[species_id] = 1\n",
    "        \n",
    "        return {\"waveform\": y.astype(np.float32), \"targets\": target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "\n",
    "\n",
    "def init_weights(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find(\"Conv2d\") != -1:\n",
    "        nn.init.xavier_uniform_(model.weight, gain=np.sqrt(2))\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        model.weight.data.normal_(1.0, 0.02)\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"GRU\") != -1:\n",
    "        for weight in model.parameters():\n",
    "            if len(weight.size()) > 1:\n",
    "                nn.init.orghogonal_(weight.data)\n",
    "    elif classname.find(\"Linear\") != -1:\n",
    "        model.weight.data.normal_(0, 0.01)\n",
    "        model.bias.data.zero_()\n",
    "\n",
    "\n",
    "def do_mixup(x: torch.Tensor, mixup_lambda: torch.Tensor):\n",
    "    \"\"\"Mixup x of even indexes (0, 2, 4, ...) with x of odd indexes\n",
    "    (1, 3, 5, ...).\n",
    "    Args:\n",
    "      x: (batch_size * 2, ...)\n",
    "      mixup_lambda: (batch_size * 2,)\n",
    "    Returns:\n",
    "      out: (batch_size, ...)\n",
    "    \"\"\"\n",
    "    out = (x[0::2].transpose(0, -1) * mixup_lambda[0::2] +\n",
    "           x[1::2].transpose(0, -1) * mixup_lambda[1::2]).transpose(0, -1)\n",
    "    return out\n",
    "\n",
    "\n",
    "class Mixup(object):\n",
    "    def __init__(self, mixup_alpha, random_seed=1234):\n",
    "        \"\"\"Mixup coefficient generator.\n",
    "        \"\"\"\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "        self.random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    def get_lambda(self, batch_size):\n",
    "        \"\"\"Get mixup random coefficients.\n",
    "        Args:\n",
    "          batch_size: int\n",
    "        Returns:\n",
    "          mixup_lambdas: (batch_size,)\n",
    "        \"\"\"\n",
    "        mixup_lambdas = []\n",
    "        for n in range(0, batch_size, 2):\n",
    "            lam = self.random_state.beta(self.mixup_alpha, self.mixup_alpha, 1)[0]\n",
    "            mixup_lambdas.append(lam)\n",
    "            mixup_lambdas.append(1. - lam)\n",
    "\n",
    "        return torch.from_numpy(np.array(mixup_lambdas, dtype=np.float32))\n",
    "\n",
    "\n",
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "\n",
    "def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n",
    "    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n",
    "    is the same as the value of the last frame.\n",
    "    Args:\n",
    "      framewise_output: (batch_size, frames_num, classes_num)\n",
    "      frames_num: int, number of frames to pad\n",
    "    Outputs:\n",
    "      output: (batch_size, frames_num, classes_num)\n",
    "    \"\"\"\n",
    "    pad = framewise_output[:, -1:, :].repeat(\n",
    "        1, frames_num - framewise_output.shape[1], 1)\n",
    "    \"\"\"tensor for padding\"\"\"\n",
    "\n",
    "    output = torch.cat((framewise_output, pad), dim=1)\n",
    "    \"\"\"(batch_size, frames_num, classes_num)\"\"\"\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttBlockV2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetSED(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_model_name: str,\n",
    "        pretrained=False,\n",
    "        num_classes=24,\n",
    "        spectrogram_params={},\n",
    "        logmel_extractor_params={},\n",
    "        spec_augmenter_params={},\n",
    "        pce_params={}\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.spectrogram_extractor = Spectrogram(**spectrogram_params)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(**logmel_extractor_params)\n",
    "        \n",
    "        #Pcen converter\n",
    "        self.pcen_converter = spec.pcen(**pce_params)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(**spec_augmenter_params)\n",
    "        \n",
    "        self.interpolate_ratio = 30  # Downsampled ratio\n",
    "        self.mixup_alpha = 0.2\n",
    "        self.random_state = np.random.RandomState(123)\n",
    "        \n",
    "        if pretrained:\n",
    "            self.base_model = EfficientNet.from_pretrained(base_model_name)\n",
    "        else:\n",
    "            self.base_model = EfficientNet.from_name(base_model_name)\n",
    "\n",
    "        in_features = self.base_model._fc.in_features\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n",
    "        self.att_block = AttBlockV2(in_features, num_classes, activation=\"sigmoid\")\n",
    "\n",
    "        self.init_weight()\n",
    "        \n",
    "    def mixup(self, x):\n",
    "        sizws = x.size()\n",
    "        #lam = torch.from_numpy(self.random_state.beta(self.mixup_alpha, self.mixup_alpha, (sizws[0], 1))).cuda()\n",
    "        lam = self.random_state.beta(self.mixup_alpha, self.mixup_alpha, 1)[0]\n",
    "        index = list(range(x.size(0)))\n",
    "        random.shuffle(index)\n",
    "        #out = (x.view(sizws[0], -1) * lam + x[index].squeeze().view(sizws[0], -1) * (1-lam)).view(sizws[0], sizws[1], sizws[2], sizws[3],)\n",
    "        out = (x * lam + x[index].squeeze() * (1-lam))\n",
    "        return out.float(), {'lam': lam, 'index': index}\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_layer(self.fc1)\n",
    "\n",
    "    def forward(self, input):        \n",
    "        x = self.spectrogram_extractor(input)\n",
    "        x = self.logmel_extractor(x)\n",
    "        \n",
    "        x_mels = self.logmel_extractor.power_to_db(x)\n",
    "        x_pcen = self.pcen_converter(x) \n",
    "        x_clear = self.logmel_extractor.power_to_db(x ** 1.5)\n",
    "        \n",
    "        \n",
    "        x = torch.cat((x_mels,x_pcen,x_clear),1)\n",
    "        #x = torch.cat((x,x,x),1)\n",
    "        \n",
    "        frames_num = x.size(2)\n",
    "        \n",
    "        if self.training:\n",
    "            x, mix_info = self.mixup(x)\n",
    "            x = self.spec_augmenter(x)\n",
    "        else:\n",
    "            mix_info = None\n",
    "                \n",
    "        # (batch_size, channels, freq, frames)\n",
    "        x = self.base_model.extract_features(x)\n",
    "\n",
    "        # (batch_size, channels, frames)\n",
    "        x = torch.mean(x, dim=3)\n",
    "\n",
    "        # channel smoothing\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n",
    "        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        # Get framewise output\n",
    "        framewise_output = interpolate(segmentwise_output,\n",
    "                                       self.interpolate_ratio)\n",
    "        framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
    "\n",
    "        framewise_logit = interpolate(segmentwise_logit, self.interpolate_ratio)\n",
    "        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n",
    "\n",
    "        output_dict = {\n",
    "            \"framewise_output\": framewise_output,\n",
    "            \"segmentwise_output\": segmentwise_output,\n",
    "            \"logit\": logit,\n",
    "            \"framewise_logit\": framewise_logit,\n",
    "            \"clipwise_output\": clipwise_output,\n",
    "            \"mixup\": mix_info\n",
    "        }\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logit, target):\n",
    "        target = target.float()\n",
    "        max_val = (-logit).clamp(min=0)\n",
    "        loss = logit - logit * target + max_val + \\\n",
    "            ((-max_val).exp() + (-logit - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-logit * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        if len(loss.size()) == 2:\n",
    "            loss = loss.sum(dim=1)\n",
    "        return loss.mean()\n",
    "\n",
    "class ImprovedFocalLoss(nn.Module):\n",
    "    def __init__(self, weights=[1, 1]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.focal = FocalLoss()\n",
    "        self.focal2 = FocalLoss()\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, input, target, mixup_info=None):\n",
    "        input_ = input[\"logit\"]\n",
    "        target = target.float()\n",
    "\n",
    "        framewise_output = input[\"framewise_logit\"]\n",
    "        clipwise_output_with_max, _ = framewise_output.max(dim=1)\n",
    "\n",
    "        normal_loss = self.focal(input_, target)\n",
    "        auxiliary_loss = self.focal(clipwise_output_with_max, target)\n",
    "        \n",
    "        loss1 = self.weights[0] * normal_loss + self.weights[1] * auxiliary_loss\n",
    "        \n",
    "        if mixup_info is None:\n",
    "            return loss1\n",
    "        else:\n",
    "            normal_loss_mix = self.focal2(input_, target[mix_info['index']].squeeze())\n",
    "            auxiliary_loss_mix = self.focal2(clipwise_output_with_max, target[mix_info['index']].squeeze())\n",
    "            loss2 = self.weights[0] * normal_loss_mix + self.weights[1] * auxiliary_loss_mix\n",
    "            \n",
    "            return loss1 * mix_info['lam'] + loss2 * (1 - mix_info['lam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LWLRAP(Callback):\n",
    "    def __init__(self,\n",
    "                 input_key: str = \"targets\",\n",
    "                 output_key: str = \"logits\",\n",
    "                 model_output_key: str = \"framewise_output\",\n",
    "                 mixup_key: str = 'mixup',\n",
    "                 prefix: str = \"LWLRAP\"):\n",
    "        super().__init__(CallbackOrder.Metric)\n",
    "        self.input_key = input_key\n",
    "        self.output_key = output_key\n",
    "        self.model_output_key = model_output_key\n",
    "        self.mixup_key = mixup_key\n",
    "        self.prefix = prefix\n",
    "        \n",
    "    def LWLRAP(self, preds, labels):\n",
    "        # Ranks of the predictions\n",
    "        ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
    "        # i, j corresponds to rank of prediction in row i\n",
    "        class_ranks = torch.zeros_like(ranked_classes)\n",
    "        for i in range(ranked_classes.size(0)):\n",
    "            for j in range(ranked_classes.size(1)):\n",
    "                class_ranks[i, ranked_classes[i][j]] = j + 1\n",
    "        # Mask out to only use the ranks of relevant GT labels\n",
    "        ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
    "        # All the GT ranks are in front now\n",
    "        sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
    "        # Number of GT labels per instance\n",
    "        num_labels = labels.sum(-1)\n",
    "        pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
    "        score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
    "        score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
    "        scores = score_matrix * score_mask_matrix\n",
    "        score = scores.sum() / labels.sum()\n",
    "        return score.item()\n",
    "    \n",
    "    def mixup_socre(self, cor, x, y, mix_info):\n",
    "        return cor(x, y) * mix_info['lam'] + cor(x, y[mix_info['index']].squeeze()) * (1-mix_info['lam'])\n",
    "\n",
    "    def on_batch_start(self, state: State):\n",
    "        self.batch_score_train: List[np.ndarray] = []\n",
    "        self.batch_score_val: List[np.ndarray] = []\n",
    "        \n",
    "    def on_batch_end(self, state: State):\n",
    "        targ = state.input[self.input_key].detach().cpu()\n",
    "        out = state.output[self.output_key]\n",
    "        mixup_info = out[self.mixup_key]\n",
    "\n",
    "        framewise_logit = out[self.model_output_key].detach().cpu().max(1)[0]\n",
    "\n",
    "        if mixup_info is None:\n",
    "            score = self.LWLRAP(framewise_logit, targ)\n",
    "        else:\n",
    "            score = self.mixup_socre(self.LWLRAP, framewise_logit, targ, mixup_info)\n",
    "        \n",
    "        state.batch_metrics[self.prefix] = score\n",
    "        \n",
    "        if state.is_valid_loader:\n",
    "            self.batch_score_val.append(score)\n",
    "        else:\n",
    "            self.batch_score_train.append(score)\n",
    "\n",
    "    def on_loader_end(self, state: State):\n",
    "        if state.is_valid_loader:\n",
    "            score = np.mean(self.batch_score_val)\n",
    "            state.loader_metrics[self.prefix] = score\n",
    "            state.epoch_metrics[state.valid_loader + \"_epoch_\" +\n",
    "                                self.prefix] = score\n",
    "        else:\n",
    "            score = np.mean(self.batch_score_train)\n",
    "            state.loader_metrics[self.prefix] = score\n",
    "            state.epoch_metrics[\"train_epoch_\" + self.prefix] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tp = pd.read_csv('../../data/train_tp.csv')\n",
    "train_fp = pd.read_csv('../../data/train_fp.csv')\n",
    "submission = pd.read_csv('../../data/sample_submission.csv')\n",
    "\n",
    "pred_target = list(submission.columns)[1:]\n",
    "SR = settings['SR']\n",
    "\n",
    "skf = StratifiedKFold(n_splits=settings['n_splits'], shuffle=True, random_state=42)\n",
    "\n",
    "train_tp[\"fold\"] = -1\n",
    "for fold_id, (train_index, val_index) in enumerate(skf.split(train_tp, train_tp[\"species_id\"])):\n",
    "    train_tp.iloc[val_index, -1] = fold_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- fold 0 ----------\n",
      "[fold 0] train: 972, val: 244\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "1/35 * Epoch (train): 100% 61/61 [00:28<00:00,  2.13it/s, LWLRAP=0.214, loss=2.094]\n",
      "1/35 * Epoch (valid): 100% 16/16 [00:05<00:00,  3.09it/s, LWLRAP=0.300, loss=3.557]\n",
      "[2021-01-24 12:58:07,233] \n",
      "1/35 * Epoch 1 (_base): lr=0.0006 | momentum=0.9000\n",
      "1/35 * Epoch 1 (train): LWLRAP=0.1867 | epoch_LWLRAP=0.2137 | loss=4.2835\n",
      "1/35 * Epoch 1 (valid): LWLRAP=0.1869 | epoch_LWLRAP=0.2998 | loss=3.4557\n",
      "2/35 * Epoch (train): 100% 61/61 [00:29<00:00,  2.09it/s, LWLRAP=0.282, loss=1.945]\n",
      "2/35 * Epoch (valid): 100% 16/16 [00:06<00:00,  2.29it/s, LWLRAP=0.140, loss=3.303]\n",
      "[2021-01-24 12:58:43,843] \n",
      "2/35 * Epoch 2 (_base): lr=0.0007 | momentum=0.9000\n",
      "2/35 * Epoch 2 (train): LWLRAP=0.2160 | epoch_LWLRAP=0.2821 | loss=2.1258\n",
      "2/35 * Epoch 2 (valid): LWLRAP=0.2248 | epoch_LWLRAP=0.1396 | loss=3.0784\n",
      "3/35 * Epoch (train): 100% 61/61 [00:30<00:00,  2.03it/s, LWLRAP=0.333, loss=1.741]\n",
      "3/35 * Epoch (valid): 100% 16/16 [00:07<00:00,  2.21it/s, LWLRAP=0.409, loss=1.859]\n",
      "[2021-01-24 12:59:21,611] \n",
      "3/35 * Epoch 3 (_base): lr=0.0007 | momentum=0.9000\n",
      "3/35 * Epoch 3 (train): LWLRAP=0.2189 | epoch_LWLRAP=0.3331 | loss=1.9914\n",
      "3/35 * Epoch 3 (valid): LWLRAP=0.2580 | epoch_LWLRAP=0.4090 | loss=2.0436\n",
      "4/35 * Epoch (train): 100% 61/61 [00:27<00:00,  2.22it/s, LWLRAP=0.180, loss=1.851]\n",
      "4/35 * Epoch (valid): 100% 16/16 [00:05<00:00,  2.97it/s, LWLRAP=0.219, loss=1.611]\n",
      "[2021-01-24 12:59:54,952] \n",
      "4/35 * Epoch 4 (_base): lr=0.0008 | momentum=0.9000\n",
      "4/35 * Epoch 4 (train): LWLRAP=0.2447 | epoch_LWLRAP=0.1797 | loss=1.9017\n",
      "4/35 * Epoch 4 (valid): LWLRAP=0.2866 | epoch_LWLRAP=0.2194 | loss=1.7084\n",
      "5/35 * Epoch (train): 100% 61/61 [00:29<00:00,  2.06it/s, LWLRAP=0.321, loss=1.979]\n",
      "5/35 * Epoch (valid): 100% 16/16 [00:06<00:00,  2.30it/s, LWLRAP=0.471, loss=1.518]\n",
      "[2021-01-24 13:00:31,920] \n",
      "5/35 * Epoch 5 (_base): lr=0.0008 | momentum=0.9000\n",
      "5/35 * Epoch 5 (train): LWLRAP=0.2495 | epoch_LWLRAP=0.3212 | loss=1.8884\n",
      "5/35 * Epoch 5 (valid): LWLRAP=0.2897 | epoch_LWLRAP=0.4708 | loss=1.7054\n",
      "6/35 * Epoch (train): 100% 61/61 [00:29<00:00,  2.09it/s, LWLRAP=0.246, loss=1.783]\n",
      "6/35 * Epoch (valid): 100% 16/16 [00:06<00:00,  2.60it/s, LWLRAP=0.750, loss=1.370]\n",
      "[2021-01-24 13:01:07,643] \n",
      "6/35 * Epoch 6 (_base): lr=0.0009 | momentum=0.9000\n",
      "6/35 * Epoch 6 (train): LWLRAP=0.2565 | epoch_LWLRAP=0.2459 | loss=1.8696\n",
      "6/35 * Epoch 6 (valid): LWLRAP=0.3643 | epoch_LWLRAP=0.7500 | loss=1.5956\n",
      "7/35 * Epoch (train): 100% 61/61 [00:30<00:00,  2.02it/s, LWLRAP=0.383, loss=1.647]\n",
      "7/35 * Epoch (valid): 100% 16/16 [00:07<00:00,  2.17it/s, LWLRAP=0.600, loss=1.409]\n",
      "[2021-01-24 13:01:45,699] \n",
      "7/35 * Epoch 7 (_base): lr=0.0009 | momentum=0.9000\n",
      "7/35 * Epoch 7 (train): LWLRAP=0.2782 | epoch_LWLRAP=0.3828 | loss=1.8441\n",
      "7/35 * Epoch 7 (valid): LWLRAP=0.3920 | epoch_LWLRAP=0.6000 | loss=1.5927\n",
      "8/35 * Epoch (train): 100% 61/61 [00:28<00:00,  2.13it/s, LWLRAP=0.434, loss=1.843]\n",
      "8/35 * Epoch (valid): 100% 16/16 [00:06<00:00,  2.59it/s, LWLRAP=0.608, loss=1.324]\n",
      "[2021-01-24 13:02:20,875] \n",
      "8/35 * Epoch 8 (_base): lr=0.0010 | momentum=0.9000\n",
      "8/35 * Epoch 8 (train): LWLRAP=0.3381 | epoch_LWLRAP=0.4335 | loss=1.7954\n",
      "8/35 * Epoch 8 (valid): LWLRAP=0.4128 | epoch_LWLRAP=0.6083 | loss=1.5385\n",
      "9/35 * Epoch (train): 100% 61/61 [00:30<00:00,  1.99it/s, LWLRAP=0.367, loss=1.929]\n",
      "9/35 * Epoch (valid): 100% 16/16 [00:07<00:00,  2.04it/s, LWLRAP=0.604, loss=1.350]\n",
      "[2021-01-24 13:02:59,785] \n",
      "9/35 * Epoch 9 (_base): lr=0.0010 | momentum=0.9000\n",
      "9/35 * Epoch 9 (train): LWLRAP=0.3382 | epoch_LWLRAP=0.3667 | loss=1.8109\n",
      "9/35 * Epoch 9 (valid): LWLRAP=0.4423 | epoch_LWLRAP=0.6042 | loss=1.4989\n",
      "10/35 * Epoch (train): 100% 61/61 [00:29<00:00,  2.10it/s, LWLRAP=0.447, loss=1.843]\n",
      "10/35 * Epoch (valid): 100% 16/16 [00:06<00:00,  2.29it/s, LWLRAP=0.750, loss=1.153]\n",
      "[2021-01-24 13:03:36,300] \n",
      "10/35 * Epoch 10 (_base): lr=0.0010 | momentum=0.9000\n",
      "10/35 * Epoch 10 (train): LWLRAP=0.3802 | epoch_LWLRAP=0.4472 | loss=1.7712\n",
      "10/35 * Epoch 10 (valid): LWLRAP=0.4920 | epoch_LWLRAP=0.7500 | loss=1.4196\n",
      "11/35 * Epoch (train): 100% 61/61 [00:29<00:00,  2.08it/s, LWLRAP=0.422, loss=1.849]\n",
      "11/35 * Epoch (valid): 100% 16/16 [00:06<00:00,  2.33it/s, LWLRAP=0.781, loss=1.121]\n",
      "[2021-01-24 13:04:12,980] \n",
      "11/35 * Epoch 11 (_base): lr=0.0010 | momentum=0.9000\n",
      "11/35 * Epoch 11 (train): LWLRAP=0.4267 | epoch_LWLRAP=0.4218 | loss=1.7604\n",
      "11/35 * Epoch 11 (valid): LWLRAP=0.4778 | epoch_LWLRAP=0.7812 | loss=1.4636\n",
      "12/35 * Epoch (train): 100% 61/61 [00:28<00:00,  2.14it/s, LWLRAP=0.371, loss=1.588]\n",
      "12/35 * Epoch (valid): 100% 16/16 [00:05<00:00,  2.73it/s, LWLRAP=0.688, loss=1.072]\n",
      "[2021-01-24 13:04:47,681] \n",
      "12/35 * Epoch 12 (_base): lr=0.0010 | momentum=0.9000\n",
      "12/35 * Epoch 12 (train): LWLRAP=0.3991 | epoch_LWLRAP=0.3709 | loss=1.7609\n",
      "12/35 * Epoch 12 (valid): LWLRAP=0.4995 | epoch_LWLRAP=0.6875 | loss=1.3648\n",
      "13/35 * Epoch (train): 100% 61/61 [00:29<00:00,  2.10it/s, LWLRAP=0.435, loss=1.893]\n",
      "13/35 * Epoch (valid): 100% 16/16 [00:06<00:00,  2.55it/s, LWLRAP=1.000, loss=0.942]\n",
      "[2021-01-24 13:05:23,457] \n",
      "13/35 * Epoch 13 (_base): lr=0.0009 | momentum=0.9000\n",
      "13/35 * Epoch 13 (train): LWLRAP=0.4336 | epoch_LWLRAP=0.4349 | loss=1.7612\n",
      "13/35 * Epoch 13 (valid): LWLRAP=0.5443 | epoch_LWLRAP=1.0000 | loss=1.3692\n",
      "14/35 * Epoch (train): 100% 61/61 [00:28<00:00,  2.14it/s, LWLRAP=0.431, loss=1.526]\n",
      "14/35 * Epoch (valid): 100% 16/16 [00:06<00:00,  2.66it/s, LWLRAP=0.765, loss=1.320]\n",
      "[2021-01-24 13:05:58,454] \n",
      "14/35 * Epoch 14 (_base): lr=0.0009 | momentum=0.9000\n",
      "14/35 * Epoch 14 (train): LWLRAP=0.4648 | epoch_LWLRAP=0.4313 | loss=1.7591\n",
      "14/35 * Epoch 14 (valid): LWLRAP=0.5057 | epoch_LWLRAP=0.7647 | loss=1.4242\n",
      "15/35 * Epoch (train): 100% 61/61 [00:28<00:00,  2.17it/s, LWLRAP=0.566, loss=2.048]\n",
      "15/35 * Epoch (valid): 100% 16/16 [00:05<00:00,  3.03it/s, LWLRAP=0.875, loss=1.004]\n",
      "[2021-01-24 13:06:32,101] \n",
      "15/35 * Epoch 15 (_base): lr=0.0009 | momentum=0.9000\n",
      "15/35 * Epoch 15 (train): LWLRAP=0.4491 | epoch_LWLRAP=0.5657 | loss=1.7791\n",
      "15/35 * Epoch 15 (valid): LWLRAP=0.5968 | epoch_LWLRAP=0.8750 | loss=1.2722\n",
      "16/35 * Epoch (train): 100% 61/61 [00:28<00:00,  2.13it/s, LWLRAP=0.458, loss=1.561]\n",
      "16/35 * Epoch (valid): 100% 16/16 [00:06<00:00,  2.64it/s, LWLRAP=0.708, loss=1.077]\n",
      "[2021-01-24 13:07:07,222] \n",
      "16/35 * Epoch 16 (_base): lr=0.0008 | momentum=0.9000\n",
      "16/35 * Epoch 16 (train): LWLRAP=0.5398 | epoch_LWLRAP=0.4578 | loss=1.6388\n",
      "16/35 * Epoch 16 (valid): LWLRAP=0.5394 | epoch_LWLRAP=0.7083 | loss=1.3310\n",
      "17/35 * Epoch (train): 100% 61/61 [00:28<00:00,  2.17it/s, LWLRAP=0.513, loss=1.946]\n",
      "17/35 * Epoch (valid): 100% 16/16 [00:05<00:00,  2.74it/s, LWLRAP=1.000, loss=0.995]\n",
      "[2021-01-24 13:07:41,472] \n",
      "17/35 * Epoch 17 (_base): lr=0.0008 | momentum=0.9000\n",
      "17/35 * Epoch 17 (train): LWLRAP=0.5540 | epoch_LWLRAP=0.5126 | loss=1.6387\n",
      "17/35 * Epoch 17 (valid): LWLRAP=0.6240 | epoch_LWLRAP=1.0000 | loss=1.2583\n",
      "18/35 * Epoch (train): 100% 61/61 [00:29<00:00,  2.10it/s, LWLRAP=0.375, loss=1.698]\n",
      "18/35 * Epoch (valid): 100% 16/16 [00:06<00:00,  2.42it/s, LWLRAP=1.000, loss=0.829]\n",
      "[2021-01-24 13:08:17,584] \n",
      "18/35 * Epoch 18 (_base): lr=0.0007 | momentum=0.9000\n",
      "18/35 * Epoch 18 (train): LWLRAP=0.5613 | epoch_LWLRAP=0.3747 | loss=1.6670\n",
      "18/35 * Epoch 18 (valid): LWLRAP=0.6048 | epoch_LWLRAP=1.0000 | loss=1.2731\n",
      "19/35 * Epoch (train): 100% 61/61 [00:31<00:00,  1.97it/s, LWLRAP=0.497, loss=1.467]\n",
      "19/35 * Epoch (valid): 100% 16/16 [00:08<00:00,  1.93it/s, LWLRAP=0.875, loss=0.982]\n",
      "[2021-01-24 13:08:57,192] \n",
      "19/35 * Epoch 19 (_base): lr=0.0007 | momentum=0.9000\n",
      "19/35 * Epoch 19 (train): LWLRAP=0.6097 | epoch_LWLRAP=0.4970 | loss=1.6610\n",
      "19/35 * Epoch 19 (valid): LWLRAP=0.6215 | epoch_LWLRAP=0.8750 | loss=1.2788\n",
      "20/35 * Epoch (train): 100% 61/61 [00:29<00:00,  2.10it/s, LWLRAP=0.806, loss=1.234]\n",
      "20/35 * Epoch (valid): 100% 16/16 [00:06<00:00,  2.49it/s, LWLRAP=1.000, loss=0.887]\n",
      "[2021-01-24 13:09:32,973] \n",
      "20/35 * Epoch 20 (_base): lr=0.0006 | momentum=0.9000\n",
      "20/35 * Epoch 20 (train): LWLRAP=0.6089 | epoch_LWLRAP=0.8063 | loss=1.6853\n",
      "20/35 * Epoch 20 (valid): LWLRAP=0.6577 | epoch_LWLRAP=1.0000 | loss=1.2422\n",
      "21/35 * Epoch (train): 100% 61/61 [00:28<00:00,  2.16it/s, LWLRAP=0.530, loss=2.117]\n",
      "21/35 * Epoch (valid): 100% 16/16 [00:05<00:00,  2.84it/s, LWLRAP=0.875, loss=1.002]\n",
      "[2021-01-24 13:10:07,318] \n",
      "21/35 * Epoch 21 (_base): lr=0.0005 | momentum=0.9000\n",
      "21/35 * Epoch 21 (train): LWLRAP=0.6298 | epoch_LWLRAP=0.5299 | loss=1.5178\n",
      "21/35 * Epoch 21 (valid): LWLRAP=0.7179 | epoch_LWLRAP=0.8750 | loss=1.2429\n",
      "22/35 * Epoch (train): 100% 61/61 [00:28<00:00,  2.13it/s, LWLRAP=0.837, loss=1.263]\n",
      "22/35 * Epoch (valid): 100% 16/16 [00:05<00:00,  2.85it/s, LWLRAP=1.000, loss=0.706]\n",
      "[2021-01-24 13:10:41,941] \n",
      "22/35 * Epoch 22 (_base): lr=0.0005 | momentum=0.9000\n",
      "22/35 * Epoch 22 (train): LWLRAP=0.6162 | epoch_LWLRAP=0.8366 | loss=1.6407\n",
      "22/35 * Epoch 22 (valid): LWLRAP=0.7181 | epoch_LWLRAP=1.0000 | loss=1.1338\n",
      "23/35 * Epoch (train): 100% 61/61 [00:28<00:00,  2.13it/s, LWLRAP=0.684, loss=1.949]\n",
      "23/35 * Epoch (valid): 100% 16/16 [00:05<00:00,  2.77it/s, LWLRAP=1.000, loss=0.739]\n",
      "[2021-01-24 13:11:16,808] \n",
      "23/35 * Epoch 23 (_base): lr=0.0004 | momentum=0.9000\n",
      "23/35 * Epoch 23 (train): LWLRAP=0.6481 | epoch_LWLRAP=0.6845 | loss=1.5554\n",
      "23/35 * Epoch 23 (valid): LWLRAP=0.7386 | epoch_LWLRAP=1.0000 | loss=1.0952\n",
      "24/35 * Epoch (train): 100% 61/61 [00:29<00:00,  2.06it/s, LWLRAP=0.769, loss=1.184]\n",
      "24/35 * Epoch (valid): 100% 16/16 [00:06<00:00,  2.39it/s, LWLRAP=1.000, loss=0.752]\n",
      "[2021-01-24 13:11:53,599] \n",
      "24/35 * Epoch 24 (_base): lr=0.0003 | momentum=0.9000\n",
      "24/35 * Epoch 24 (train): LWLRAP=0.6808 | epoch_LWLRAP=0.7688 | loss=1.6790\n",
      "24/35 * Epoch 24 (valid): LWLRAP=0.7271 | epoch_LWLRAP=1.0000 | loss=1.1281\n",
      "25/35 * Epoch (train): 100% 61/61 [00:29<00:00,  2.06it/s, LWLRAP=0.676, loss=1.125]\n",
      "25/35 * Epoch (valid): 100% 16/16 [00:06<00:00,  2.30it/s, LWLRAP=1.000, loss=0.894]\n",
      "[2021-01-24 13:12:30,430] \n",
      "25/35 * Epoch 25 (_base): lr=0.0003 | momentum=0.9000\n",
      "25/35 * Epoch 25 (train): LWLRAP=0.6934 | epoch_LWLRAP=0.6763 | loss=1.5920\n",
      "25/35 * Epoch 25 (valid): LWLRAP=0.7624 | epoch_LWLRAP=1.0000 | loss=1.0374\n",
      "26/35 * Epoch (train): 100% 61/61 [00:29<00:00,  2.06it/s, LWLRAP=0.469, loss=1.450]\n",
      "26/35 * Epoch (valid): 100% 16/16 [00:07<00:00,  2.26it/s, LWLRAP=1.000, loss=0.677]\n",
      "[2021-01-24 13:13:07,562] \n",
      "26/35 * Epoch 26 (_base): lr=0.0002 | momentum=0.9000\n",
      "26/35 * Epoch 26 (train): LWLRAP=0.6786 | epoch_LWLRAP=0.4690 | loss=1.5576\n",
      "26/35 * Epoch 26 (valid): LWLRAP=0.7700 | epoch_LWLRAP=1.0000 | loss=1.0043\n",
      "27/35 * Epoch (train): 100% 61/61 [00:29<00:00,  2.06it/s, LWLRAP=0.668, loss=1.231]\n",
      "27/35 * Epoch (valid): 100% 16/16 [00:07<00:00,  2.24it/s, LWLRAP=1.000, loss=0.730]\n",
      "[2021-01-24 13:13:44,812] \n",
      "27/35 * Epoch 27 (_base): lr=0.0002 | momentum=0.9000\n",
      "27/35 * Epoch 27 (train): LWLRAP=0.6974 | epoch_LWLRAP=0.6675 | loss=1.4908\n",
      "27/35 * Epoch 27 (valid): LWLRAP=0.7860 | epoch_LWLRAP=1.0000 | loss=0.9573\n",
      "28/35 * Epoch (train): 100% 61/61 [00:30<00:00,  2.03it/s, LWLRAP=0.545, loss=1.785]\n",
      "28/35 * Epoch (valid): 100% 16/16 [00:07<00:00,  2.13it/s, LWLRAP=1.000, loss=0.459]\n",
      "[2021-01-24 13:14:22,870] \n",
      "28/35 * Epoch 28 (_base): lr=0.0001 | momentum=0.9000\n",
      "28/35 * Epoch 28 (train): LWLRAP=0.7085 | epoch_LWLRAP=0.5454 | loss=1.4719\n",
      "28/35 * Epoch 28 (valid): LWLRAP=0.7783 | epoch_LWLRAP=1.0000 | loss=0.9158\n",
      "29/35 * Epoch (train): 100% 61/61 [00:27<00:00,  2.24it/s, LWLRAP=0.531, loss=1.702]\n",
      "29/35 * Epoch (valid): 100% 16/16 [00:04<00:00,  3.43it/s, LWLRAP=1.000, loss=0.672]\n",
      "[2021-01-24 13:14:55,059] \n",
      "29/35 * Epoch 29 (_base): lr=9.549e-05 | momentum=0.9000\n",
      "29/35 * Epoch 29 (train): LWLRAP=0.7181 | epoch_LWLRAP=0.5306 | loss=1.4900\n",
      "29/35 * Epoch 29 (valid): LWLRAP=0.7903 | epoch_LWLRAP=1.0000 | loss=0.8917\n",
      "30/35 * Epoch (train): 100% 61/61 [00:28<00:00,  2.15it/s, LWLRAP=0.853, loss=1.050]\n",
      "30/35 * Epoch (valid): 100% 16/16 [00:05<00:00,  2.78it/s, LWLRAP=1.000, loss=0.625]\n",
      "[2021-01-24 13:15:29,558] \n",
      "30/35 * Epoch 30 (_base): lr=6.185e-05 | momentum=0.9000\n",
      "30/35 * Epoch 30 (train): LWLRAP=0.7473 | epoch_LWLRAP=0.8535 | loss=1.5467\n",
      "30/35 * Epoch 30 (valid): LWLRAP=0.7820 | epoch_LWLRAP=1.0000 | loss=0.9717\n",
      "31/35 * Epoch (train): 100% 61/61 [00:27<00:00,  2.20it/s, LWLRAP=0.632, loss=2.087]\n",
      "31/35 * Epoch (valid): 100% 16/16 [00:05<00:00,  3.17it/s, LWLRAP=1.000, loss=0.597]\n",
      "[2021-01-24 13:16:02,616] \n",
      "31/35 * Epoch 31 (_base): lr=3.511e-05 | momentum=0.9000\n",
      "31/35 * Epoch 31 (train): LWLRAP=0.7529 | epoch_LWLRAP=0.6319 | loss=1.5125\n",
      "31/35 * Epoch 31 (valid): LWLRAP=0.8152 | epoch_LWLRAP=1.0000 | loss=0.9261\n",
      "32/35 * Epoch (train): 100% 61/61 [00:27<00:00,  2.22it/s, LWLRAP=0.917, loss=0.932]\n",
      "32/35 * Epoch (valid): 100% 16/16 [00:04<00:00,  3.34it/s, LWLRAP=1.000, loss=0.517]\n",
      "[2021-01-24 13:16:35,292] \n",
      "32/35 * Epoch 32 (_base): lr=1.571e-05 | momentum=0.9000\n",
      "32/35 * Epoch 32 (train): LWLRAP=0.7600 | epoch_LWLRAP=0.9167 | loss=1.4165\n",
      "32/35 * Epoch 32 (valid): LWLRAP=0.8063 | epoch_LWLRAP=1.0000 | loss=0.8894\n",
      "33/35 * Epoch (train): 100% 61/61 [00:27<00:00,  2.23it/s, LWLRAP=0.545, loss=1.408]\n",
      "33/35 * Epoch (valid): 100% 16/16 [00:04<00:00,  3.42it/s, LWLRAP=1.000, loss=0.561]\n",
      "[2021-01-24 13:17:07,604] \n",
      "33/35 * Epoch 33 (_base): lr=3.943e-06 | momentum=0.9000\n",
      "33/35 * Epoch 33 (train): LWLRAP=0.7459 | epoch_LWLRAP=0.5446 | loss=1.4221\n",
      "33/35 * Epoch 33 (valid): LWLRAP=0.8015 | epoch_LWLRAP=1.0000 | loss=0.8890\n",
      "34/35 * Epoch (train): 100% 61/61 [00:29<00:00,  2.09it/s, LWLRAP=0.692, loss=1.027]\n",
      "34/35 * Epoch (valid): 100% 16/16 [00:06<00:00,  2.45it/s, LWLRAP=1.000, loss=0.552]\n",
      "[2021-01-24 13:17:43,668] \n",
      "34/35 * Epoch 34 (_base): lr=0.000e+00 | momentum=0.9000\n",
      "34/35 * Epoch 34 (train): LWLRAP=0.7484 | epoch_LWLRAP=0.6923 | loss=1.4434\n",
      "34/35 * Epoch 34 (valid): LWLRAP=0.7886 | epoch_LWLRAP=1.0000 | loss=0.9145\n",
      "35/35 * Epoch (train): 100% 61/61 [00:28<00:00,  2.13it/s, LWLRAP=0.769, loss=1.833]\n",
      "35/35 * Epoch (valid): 100% 16/16 [00:06<00:00,  2.51it/s, LWLRAP=1.000, loss=0.633]\n",
      "[2021-01-24 13:18:19,063] \n",
      "35/35 * Epoch 35 (_base): lr=3.943e-06 | momentum=0.9000\n",
      "35/35 * Epoch 35 (train): LWLRAP=0.7721 | epoch_LWLRAP=0.7685 | loss=1.4670\n",
      "35/35 * Epoch 35 (valid): LWLRAP=0.8099 | epoch_LWLRAP=1.0000 | loss=0.8879\n",
      "Top best models:\n",
      "/home/yuigahama/kaggle/rfcx/logs/catalyst_efficient_b0_base/fold0/checkpoints/train.31.pth\t0.8152\n",
      "---------- fold 1 ----------\n",
      "[fold 1] train: 973, val: 243\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "1/35 * Epoch (train): 100% 61/61 [00:27<00:00,  2.19it/s, LWLRAP=0.217, loss=2.080]\n",
      "1/35 * Epoch (valid): 100% 16/16 [00:05<00:00,  2.93it/s, LWLRAP=0.080, loss=3.858]\n",
      "[2021-01-24 13:18:53,722] \n",
      "1/35 * Epoch 1 (_base): lr=0.0006 | momentum=0.9000\n",
      "1/35 * Epoch 1 (train): LWLRAP=0.1748 | epoch_LWLRAP=0.2174 | loss=4.3166\n",
      "1/35 * Epoch 1 (valid): LWLRAP=0.2122 | epoch_LWLRAP=0.0802 | loss=3.5475\n",
      "2/35 * Epoch (train): 100% 61/61 [00:29<00:00,  2.07it/s, LWLRAP=0.205, loss=1.987]\n",
      "Early exiting                                   \n",
      "2/35 * Epoch (valid):   0% 0/16 [00:04<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_experiment_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_early_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_epoch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_loader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2c599e70a4db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m         input_target_key=\"targets\")\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     runner.train(\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/runners/runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, criterion, optimizer, scheduler, datasets, loaders, callbacks, logdir, resume, num_epochs, valid_loader, main_metric, minimize_metric, verbose, stage_kwargs, checkpoint_data, fp16, distributed, check, overfit, timeit, load_best_on_end, initial_seed, state_kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mdistributed_cmd_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     def infer(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/utils/scripts.py\u001b[0m in \u001b[0;36mdistributed_cmd_run\u001b[0;34m(worker_fn, distributed, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0mworld_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     ):\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mworker_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlocal_rank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_exception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_substring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/callbacks/checkpoint.py\u001b[0m in \u001b[0;36mon_exception\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_checkpoint_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{suffix}.exception_{exception.__class__.__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             save_checkpoint(\n\u001b[0m\u001b[1;32m    236\u001b[0m                 \u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{runner.logdir}/checkpoints/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/utils/checkpoint.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(checkpoint, logdir, suffix, is_best, is_last, special_suffix, saver_fn)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{logdir}/{suffix}.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0msaver_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_best\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{logdir}/best{special_suffix}.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;31m# Copy to a buffer, then serialize that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_should_read_directly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m             \u001b[0mbuf_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "for use_fold in range(5):\n",
    "    print(f'---------- fold {use_fold} ----------')\n",
    "    train_file_list = train_tp.query(\"fold != @use_fold\")\n",
    "    val_file_list = train_tp.query(\"fold == @use_fold\")\n",
    "\n",
    "    print(\"[fold {}] train: {}, val: {}\".format(use_fold, len(train_file_list), len(val_file_list)))\n",
    "    \n",
    "    # loaders\n",
    "    loaders = {\n",
    "        \"train\": DataLoader(\n",
    "            RfcxDataSet(train_file_list, **settings['train_params']),\n",
    "            shuffle=True,\n",
    "            **settings['dataloder_params']\n",
    "        ),\n",
    "        \"valid\": DataLoader(\n",
    "            RfcxDataSet(val_file_list, **settings['val_params']),\n",
    "            shuffle=False,\n",
    "            **settings['dataloder_params']\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # model\n",
    "    model = EfficientNetSED(**settings['model_params'])\n",
    "    model.to(device)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = Adam(model.parameters(), **settings['optim_params'])\n",
    "\n",
    "    # Scheduler\n",
    "    scheduler = wu.SimpleCosineAnnealingWarmup(optimizer, **settings['scheduler_params'])\n",
    "\n",
    "    # Loss\n",
    "    criterion = ImprovedFocalLoss(settings['loss_params']).to(device)\n",
    "\n",
    "    # callbacks\n",
    "    callbacks = [\n",
    "        LWLRAP(),\n",
    "        CheckpointCallback(save_n_best=1)\n",
    "    ]\n",
    "\n",
    "    runner = SupervisedRunner(\n",
    "        device=device,\n",
    "        input_key=\"waveform\",\n",
    "        input_target_key=\"targets\")\n",
    "\n",
    "    runner.train(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        loaders=loaders,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        num_epochs=settings['epochs'],\n",
    "        verbose=True,\n",
    "        logdir=f\"{settings['log_path']}/{settings['test_name']}/fold{use_fold}\",\n",
    "        callbacks=callbacks,\n",
    "        main_metric=\"LWLRAP\",\n",
    "        minimize_metric=False\n",
    "    )\n",
    "     \n",
    "    del model, loaders, optimizer, runner\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_for_clip(audio_id: str,\n",
    "                        clip: np.ndarray, \n",
    "                        model: EfficientNetSED,\n",
    "                        threshold=0.5):\n",
    "    PERIOD = 10\n",
    "    audios = []\n",
    "    y = clip.astype(np.float32)\n",
    "    len_y = len(y)\n",
    "    start = 0\n",
    "    end = PERIOD * SR\n",
    "    while True:\n",
    "        y_batch = y[start:end].astype(np.float32)\n",
    "\n",
    "        start = end - (5 * SR)\n",
    "        end += 5 * SR\n",
    "        \n",
    "        #mel = create_mel(y_batch)\n",
    "        audios.append(y_batch)\n",
    "        \n",
    "        if len_y < end:\n",
    "            break\n",
    "            \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    array = np.asarray(audios)\n",
    "    image = torch.from_numpy(array).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    estimated_event_list = []\n",
    "    global_time = 0.0\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(image)\n",
    "        frame_pred = torch.sum(\n",
    "            torch.sigmoid(torch.max(prediction[\"framewise_output\"], 1)[0]), 0\n",
    "        ).detach().cpu().numpy()\n",
    "        framewise_outputs = torch.max(prediction[\"framewise_output\"], 0)[0].detach(\n",
    "            ).cpu().numpy()\n",
    "        \n",
    "    thresholded = framewise_outputs >= threshold\n",
    "    \n",
    "    for target_idx in range(thresholded.shape[1]):\n",
    "        if thresholded[:, target_idx].mean() == 0:\n",
    "            pass\n",
    "        else:\n",
    "            detected = np.argwhere(thresholded[:, target_idx]).reshape(-1)\n",
    "            head_idx = 0\n",
    "            tail_idx = 0\n",
    "            while True:\n",
    "                if (tail_idx + 1 == len(detected)) or (\n",
    "                        detected[tail_idx + 1] - \n",
    "                        detected[tail_idx] != 1):\n",
    "                    onset = 0.01 * detected[\n",
    "                        head_idx] + global_time\n",
    "                    offset = 0.01 * detected[\n",
    "                        tail_idx] + global_time\n",
    "                    onset_idx = detected[head_idx]\n",
    "                    offset_idx = detected[tail_idx]\n",
    "                    max_confidence = framewise_outputs[\n",
    "                        onset_idx:offset_idx, target_idx].max()\n",
    "                    mean_confidence = framewise_outputs[\n",
    "                        onset_idx:offset_idx, target_idx].mean()\n",
    "                    estimated_event = {\n",
    "                        \"audio_id\": audio_id,\n",
    "                        \"ebird_code\": target_idx,\n",
    "                        \"onset\": onset,\n",
    "                        \"offset\": offset,\n",
    "                        \"max_confidence\": max_confidence,\n",
    "                        \"mean_confidence\": mean_confidence\n",
    "                    }\n",
    "                    estimated_event_list.append(estimated_event)\n",
    "                    head_idx = tail_idx + 1\n",
    "                    tail_idx = tail_idx + 1\n",
    "                    if head_idx >= len(detected):\n",
    "                        break\n",
    "                else:\n",
    "                    tail_idx += 1\n",
    "        global_time += PERIOD\n",
    "        \n",
    "    prediction_df = pd.DataFrame(estimated_event_list)\n",
    "    return prediction_df, frame_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(test_df: pd.DataFrame,\n",
    "               model: dict,\n",
    "               threshold=0.5):\n",
    "    #model = get_model(model_config, weights_path)\n",
    "    unique_audio_id = test_df.recording_id.unique()\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    prediction_dfs = []\n",
    "    frame_dict = dict()\n",
    "    for audio_id in tqdm(unique_audio_id):\n",
    "        clip, _ = librosa.load(\n",
    "            f'/home/yuigahama/kaggle/rfcx/data/test/{audio_id}.flac',\n",
    "            sr=SR,\n",
    "            mono=True,\n",
    "            res_type=\"kaiser_fast\"\n",
    "        )\n",
    "        \n",
    "        test_df_for_audio_id = test_df.query(\n",
    "            f\"recording_id == '{audio_id}'\").reset_index(drop=True)\n",
    "        prediction_df, frame_pred = prediction_for_clip(\n",
    "            audio_id,\n",
    "            clip=clip,\n",
    "            model=model,\n",
    "            threshold=threshold\n",
    "        )\n",
    "        frame_dict[audio_id] = frame_pred\n",
    "        prediction_dfs.append(prediction_df)\n",
    "    \n",
    "    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n",
    "    return prediction_df, frame_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "preds = []\n",
    "frams = [] \n",
    "for use_fold in range(5):\n",
    "\n",
    "    model =  EfficientNetSED(**settings['model_params']).to(device)\n",
    "    params = torch.load(f\"{settings['log_path']}/{settings['test_name']}/fold{use_fold}/checkpoints/best.pth\")\n",
    "    model.load_state_dict(params[\"model_state_dict\"])\n",
    "    \n",
    "    prediction_df, frame_dict = prediction(\n",
    "        test_df=submission,\n",
    "        model=model,\n",
    "        threshold=0.5\n",
    "    )\n",
    "    print(len(prediction_df.audio_id.unique()))\n",
    "    preds.append(prediction_df)\n",
    "    frams.append(pd.DataFrame(frame_dict).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(np.zeros((len(submission), 24)),columns=pred_target, index=submission['recording_id'])\n",
    "for p,j in zip(frams, [0.2, 0.2, 0.2, 0.2, 0.2]):\n",
    "    p.columns = pred_target\n",
    "    sub += (p * j)\n",
    "#sub /= 5\n",
    "sub.reset_index().to_csv(f\"{settings['log_path']}/{settings['test_name']}/submission_{settings['test_name']}.csv\", index=False)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
