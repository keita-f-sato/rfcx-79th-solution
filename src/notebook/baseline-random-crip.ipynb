{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuigahama/anaconda3/lib/python3.8/site-packages/torchaudio/backend/utils.py:53: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, AdamW, lr_scheduler\n",
    "from torch.distributions import Uniform\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchvision.models import resnet34, resnet50\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from libs import transform as tr\n",
    "from libs import spectrogram as spec\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tp = pd.read_csv('../../data/add_no_call.csv')\n",
    "submission = pd.read_csv('../../data/sample_submission.csv')\n",
    "\n",
    "pred_target = list(submission.columns)[1:]\n",
    "\n",
    "\n",
    "SR = 48000\n",
    "LENGTH = SR * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = False  # type: ignore\n",
    "set_seed(53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_melspec(X: np.ndarray):\n",
    "    eps = 1e-6\n",
    "    mean = X.mean()\n",
    "    X = X - mean\n",
    "    std = X.std()\n",
    "    Xstd = X / (std + eps)\n",
    "    norm_min, norm_max = Xstd.min(), Xstd.max()\n",
    "    if (norm_max - norm_min) > eps:\n",
    "        V = Xstd\n",
    "        V[V < norm_min] = norm_min\n",
    "        V[V > norm_max] = norm_max\n",
    "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        # Just zero\n",
    "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RfcxDataSet(Dataset):\n",
    "    def __init__(self,\n",
    "                 df:pd.DataFrame,\n",
    "                 data_path:str,\n",
    "    ):\n",
    "        self.df =  df\n",
    "        self.path = data_path\n",
    "        self.img_size = 256\n",
    "        \n",
    "        self.transform = tr.Compose([\n",
    "          tr.OneOf([\n",
    "            tr.GaussianNoiseSNR(min_snr=10),\n",
    "            tr.PinkNoiseSNR(min_snr=10)\n",
    "          ]),\n",
    "          #tr.PitchShift(max_steps=2, sr=SR),\n",
    "          #tr.TimeStretch(),\n",
    "          #tr.TimeShift(sr=SR),\n",
    "          #tr.VolumeControl(mode=\"sine\")\n",
    "        ])\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def get_duration(self, t_min, t_max):\n",
    "        annotated_duration = t_max - t_min\n",
    "        \n",
    "        if annotated_duration > 10:\n",
    "            limit_sec = t_max - 10\n",
    "            start_sec = random.randint(t_min, limit_sec)\n",
    "            end_sec = start_sec + 10\n",
    "            \n",
    "            start = start_sec * SR\n",
    "            end = end_sec * SR\n",
    "        else:\n",
    "            res_time = 10 - annotated_duration\n",
    "            front_limit = res_time if res_time < t_min else t_min\n",
    "            \n",
    "            front_time = random.randint(0, front_limit)\n",
    "            \n",
    "            back_limit = 60 - t_max\n",
    "            \n",
    "            tmp_time = res_time - front_time\n",
    "            back_time = tmp_time if tmp_time < back_limit else back_limit\n",
    "            \n",
    "            if not tmp_time < back_limit:\n",
    "                front_time += tmp_time - back_limit\n",
    "            \n",
    "            start = (t_min - front_time) * SR\n",
    "            end = (t_max + back_time) * SR\n",
    "            \n",
    "        return start, end\n",
    "    \n",
    "    def get_no_call(self, t_min, t_max):\n",
    "        t_min = int(t_min * 0.9)\n",
    "        t_max = int(t_max * 1.1)\n",
    "        \n",
    "        back_time = 60 - t_max\n",
    "        \n",
    "        if t_min > back_time:\n",
    "            limit = t_min - 11\n",
    "            start = random.randint(0, limit)\n",
    "        else:\n",
    "            limit = 50\n",
    "            start = random.randint(t_max+1, limit)\n",
    "        end = start + 10\n",
    "        \n",
    "        return start * SR, end * SR\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        sample = self.df.iloc[idx, :]\n",
    "        recording_id = sample['recording_id']\n",
    "        species_id = sample['species_id']\n",
    "        is_no_call = sample['is_nocall']\n",
    "        t_min = int(round(sample['t_min']))\n",
    "        t_max = int(round(sample['t_max']))\n",
    "        \n",
    "        record_path = self.path + recording_id + '.flac'\n",
    "        y, sr = librosa.load(record_path, sr=None)\n",
    "        \n",
    "        random_limit = y.shape[0] - LENGTH\n",
    "        \n",
    "        start = random.randint(0, random_limit)\n",
    "        end = start + LENGTH\n",
    "        \n",
    "        target = torch.zeros([25], dtype=torch.float32)\n",
    "        \n",
    "        if is_no_call:\n",
    "            start, end = self.get_no_call(t_min, t_max)\n",
    "            target[-1] = 1\n",
    "        else:\n",
    "            start, end = self.get_duration(t_min, t_max)\n",
    "            target[species_id] = 1\n",
    "\n",
    "        tarnsform_flag = random.choice([True, True, False])\n",
    "        \n",
    "        if tarnsform_flag:\n",
    "            y = self.transform(y)\n",
    "        \n",
    "        \n",
    "        return y[start:end], target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RfcxTestDataSet(Dataset):\n",
    "    def __init__(self,\n",
    "                 df:pd.DataFrame,\n",
    "                 data_path:str,\n",
    "                 val=False\n",
    "    ):\n",
    "        self.df =  df\n",
    "        self.val = val\n",
    "        self.path = data_path\n",
    "        self.img_size = 256\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        sample = self.df.iloc[idx, :]\n",
    "        recording_id = sample['recording_id']\n",
    "        record_path = self.path + recording_id + '.flac'\n",
    "        \n",
    "        y, sr = librosa.load(record_path, sr=None)\n",
    "        \n",
    "        images = []\n",
    "        \n",
    "        start = 0\n",
    "        for i in range(6):\n",
    "            end = start + (SR * 10)\n",
    "            images.append(y[start:end])\n",
    "            start = end\n",
    "            \n",
    "        if self.val == True:\n",
    "            species_id = sample['species_id']\n",
    "            target = torch.zeros([25], dtype=torch.float32)\n",
    "            target[species_id] = 1\n",
    "            return images, target\n",
    "        else:\n",
    "            return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_type, model_name, output_size, spectrogram_params, logmel_extractor_params, spec_augmenter_params, pce_params):\n",
    "        super().__init__()\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        self.spectrogram_extractor = Spectrogram(**spectrogram_params)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(**logmel_extractor_params)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(**spec_augmenter_params)\n",
    "        \n",
    "        #Pcen converter\n",
    "        self.pcen_converter = spec.pcen(**pce_params)\n",
    "        \n",
    "        self.bn0 = nn.BatchNorm2d(logmel_extractor_params['n_mels'])\n",
    "        \n",
    "        self.mixup_alpha = 0.2\n",
    "        self.random_state = np.random.RandomState(123)\n",
    "        \n",
    "        if model_type == 'res':\n",
    "            if model_name == 'resnet50':\n",
    "                base_model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\n",
    "            else:\n",
    "                base_model = resnet34(pretrained=True)\n",
    "            \n",
    "            layers = list(base_model.children())[:-1]\n",
    "            self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "            in_features = base_model.fc.in_features\n",
    "\n",
    "            #self.fc1 = nn.Linear(in_features, in_features, bias=True)\n",
    "            \n",
    "            self.fc1 = nn.Sequential(\n",
    "                nn.Linear(in_features, 1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.2),\n",
    "                nn.Linear(1024, 1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.2),\n",
    "                nn.Linear(1024, output_size)\n",
    "            )\n",
    "\n",
    "            \n",
    "        elif model_type == 'efficientnet':\n",
    "            self.features = EfficientNet.from_pretrained(model_name)\n",
    "            model_code = model_name.split('-')[1]\n",
    "            \n",
    "            num_input = {\n",
    "                'b4': 1792,\n",
    "                'b2': 1408,\n",
    "                'b7': 2560\n",
    "            }\n",
    "            \n",
    "            self.features_out = num_input[model_code]\n",
    "            \n",
    "            self.classification = nn.Sequential(nn.Linear(num_input[model_code], output_size))\n",
    "            \n",
    "    def mixup(self, x):\n",
    "        lam = self.random_state.beta(self.mixup_alpha, self.mixup_alpha, 1)[0]\n",
    "        index = list(range(x.size(0)))\n",
    "        random.shuffle(index)\n",
    "        out = (x * lam + x[index].squeeze() * (1-lam))\n",
    "        \n",
    "        return out, {'lam': lam, 'index': index}\n",
    "\n",
    "    def norm_spec(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        height = x.size(2)\n",
    "        width = x.size(3)\n",
    "        \n",
    "        x = x.squeeze().view(batch_size, -1)\n",
    "        \n",
    "        x -= x.min(1, keepdim=True)[0]\n",
    "        x /= x.max(1, keepdim=True)[0]\n",
    "        x = x.view(batch_size, height, width)\n",
    "        \n",
    "        return x.unsqueeze(1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        if self.model_type == 'res':\n",
    "            x = self.spectrogram_extractor(input)\n",
    "            x = self.logmel_extractor(x)\n",
    "            \n",
    "            x_mels = self.norm_spec(x)\n",
    "            x_pcen = self.norm_spec(self.pcen_converter(x))\n",
    "            x_clear = self.norm_spec(self.logmel_extractor.power_to_db(x ** 1.5))\n",
    "            \n",
    "            #x = torch.stack([self.norm_spec(x_mels), x_pcen, x_clear], dim=1).squeeze()\n",
    "            x = torch.stack([x_mels, x_pcen, x_clear], dim=1).squeeze()\n",
    "            \n",
    "            x = x.transpose(1, 3)\n",
    "            x = self.bn0(x)\n",
    "            x = x.transpose(1, 3)\n",
    "            \n",
    "            if self.training:\n",
    "                x, mix_info = self.mixup(x)\n",
    "                x = self.spec_augmenter(x)\n",
    "            else:\n",
    "                mix_info = None\n",
    "            \n",
    "            x = self.encoder(x)\n",
    "\n",
    "            x = F.dropout(x, p=0.5, training=self.training)\n",
    "            x = self.fc1(x)\n",
    "                        \n",
    "        elif self.model_type == 'efficientnet':\n",
    "            x = self.features.extract_features(input)\n",
    "            x = F.avg_pool2d(x, x.size()[2:]).reshape(-1, self.features_out)\n",
    "            x = self.classification(x)\n",
    "            \n",
    "        return x, mix_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(fold, model, optim, criterion, file_path=\"../../model/\"):\n",
    "    if not TEST_NAME in os.listdir(file_path):\n",
    "        os.mkdir(file_path+TEST_NAME)\n",
    "    \n",
    "    \n",
    "    output_path = file_path + TEST_NAME + '/' + f\"{TEST_NAME}_{fold}.model\"\n",
    "    \n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.cpu().state_dict(),\n",
    "            'optimizer_state_dict': optim.state_dict(),\n",
    "            'criterion': criterion\n",
    "        },\n",
    "        output_path)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LRAP. Instance-level average\n",
    "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
    "def LRAP(preds, labels):\n",
    "    # Ranks of the predictions\n",
    "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
    "    # i, j corresponds to rank of prediction in row i\n",
    "    class_ranks = torch.zeros_like(ranked_classes)\n",
    "    for i in range(ranked_classes.size(0)):\n",
    "        for j in range(ranked_classes.size(1)):\n",
    "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
    "    # Mask out to only use the ranks of relevant GT labels\n",
    "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
    "    # All the GT ranks are in front now\n",
    "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
    "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
    "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
    "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
    "    scores = score_matrix * score_mask_matrix\n",
    "    score = (scores.sum(-1) / labels.sum(-1)).mean()\n",
    "    return score.item()\n",
    "\n",
    "# label-level average\n",
    "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
    "def LWLRAP(preds, labels):\n",
    "    # Ranks of the predictions\n",
    "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
    "    # i, j corresponds to rank of prediction in row i\n",
    "    class_ranks = torch.zeros_like(ranked_classes)\n",
    "    for i in range(ranked_classes.size(0)):\n",
    "        for j in range(ranked_classes.size(1)):\n",
    "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
    "    # Mask out to only use the ranks of relevant GT labels\n",
    "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
    "    # All the GT ranks are in front now\n",
    "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
    "    # Number of GT labels per instance\n",
    "    num_labels = labels.sum(-1)\n",
    "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
    "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
    "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
    "    scores = score_matrix * score_mask_matrix\n",
    "    score = scores.sum() / labels.sum()\n",
    "    return score.item()\n",
    "\n",
    "def mixup_socre(cor, x, y, mix_info):\n",
    "    return cor(x, y) * mix_info['lam'] + cor(x, y[mix_info['index']].squeeze()) * (1-mix_info['lam'])\n",
    "\n",
    "# Sample usage\n",
    "# y_true = torch.tensor(np.array([[1, 1, 0], [1, 0, 1], [0, 0, 1]]))\n",
    "# y_score = torch.tensor(np.random.randn(3, 3))\n",
    "# print(LRAP(y_score, y_true), LWLRAP(y_score, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NAME = 'baseline-pic-res'\n",
    "\n",
    "n_splits = 5\n",
    "random_state = 1\n",
    "epochs = 50\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "spectrogram_params = {\n",
    "    'n_fft': 2048,\n",
    "    'hop_length': 512,\n",
    "    'win_length': 1024,\n",
    "    'window': 'hann',\n",
    "    'center': True,\n",
    "    'pad_mode': 'reflect',\n",
    "    'freeze_parameters': True\n",
    "}\n",
    "\n",
    "logmel_extractor_params = {\n",
    "    'sr': SR,\n",
    "    'n_fft': 2048,\n",
    "    'n_mels': 80,\n",
    "    'fmin': 0,\n",
    "    'fmax': 14000,\n",
    "    'ref' : 1.0,\n",
    "    'amin': 1e-10,\n",
    "    'top_db': None,\n",
    "    'is_log': False,\n",
    "    'freeze_parameters': True\n",
    "}\n",
    "\n",
    "spec_augmenter_params = {\n",
    "    'time_drop_width':  64,\n",
    "    'time_stripes_num': 2,\n",
    "    'freq_drop_width':  8,\n",
    "    'freq_stripes_num': 2\n",
    "}\n",
    "\n",
    "pce_params = {\n",
    "    'gain': 0.98,\n",
    "    'bias': 2,\n",
    "    'power': 0.5,\n",
    "    'time_constant': 0.4,\n",
    "    'eps': 0.000001,\n",
    "}\n",
    "\n",
    "model_params = {\n",
    "    'model_type': 'res', # res or efficientnet\n",
    "    'model_name': 'resnet50',\n",
    "    'output_size': 25,\n",
    "    'spectrogram_params': spectrogram_params,\n",
    "    'logmel_extractor_params': logmel_extractor_params,\n",
    "    'spec_augmenter_params': spec_augmenter_params,\n",
    "    'pce_params': pce_params\n",
    "}\n",
    "\n",
    "optim_params = {\n",
    "    'lr': 1e-3,\n",
    "    'weight_decay': 5e-5,\n",
    "    'betas': (0.9, 0.999)\n",
    "}\n",
    "\n",
    "scheduler_params = {\n",
    "    'mode': 'max',\n",
    "    'patience': 1,\n",
    "    'factor': 0.6,\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "data_params = {\n",
    "    'data_path': '/home/yuigahama/kaggle/rfcx/data/train/',\n",
    "}\n",
    "\n",
    "test_data_params = {\n",
    "    'data_path': '/home/yuigahama/kaggle/rfcx/data/test/',\n",
    "}\n",
    "\n",
    "dataloder_params = {\n",
    "    'batch_size': 64,\n",
    "    'num_workers': 15,\n",
    "    'pin_memory': False,\n",
    "}\n",
    "\n",
    "test_dataloder_params = {\n",
    "    'batch_size': 32,\n",
    "    'num_workers': 15,\n",
    "    'pin_memory': False,\n",
    "    'shuffle':False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- fold 0 ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/yuigahama/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1| T | loss: 1.33 | score: 0.206 | V | loss: 1.26 | score: 0.272 | time: 0:00:35\n",
      "epoch   2| T | loss: 1.22 | score: 0.277 | V | loss: 2.17 | score: 0.203 | time: 0:00:35\n",
      "epoch   3| T | loss: 1.15 | score: 0.329 | V | loss: 1.48 | score: 0.289 | time: 0:00:36\n",
      "epoch   4| T | loss: 1.08 | score: 0.378 | V | loss: 0.947 | score: 0.463 | time: 0:00:36\n",
      "epoch   5| T | loss: 1.01 | score: 0.429 | V | loss: 1.02 | score: 0.41 | time: 0:00:36\n",
      "epoch   6| T | loss: 0.928 | score: 0.481 | V | loss: 1.05 | score: 0.435 | time: 0:00:35\n",
      "epoch   7| T | loss: 0.862 | score: 0.53 | V | loss: 0.933 | score: 0.489 | time: 0:00:37\n",
      "epoch   8| T | loss: 0.835 | score: 0.556 | V | loss: 0.803 | score: 0.548 | time: 0:00:36\n",
      "epoch   9| T | loss: 0.776 | score: 0.605 | V | loss: 0.894 | score: 0.535 | time: 0:00:37\n",
      "epoch  10| T | loss: 0.802 | score: 0.602 | V | loss: 0.835 | score: 0.528 | time: 0:00:36\n",
      "epoch  11| T | loss: 0.833 | score: 0.587 | V | loss: 0.712 | score: 0.605 | time: 0:00:37\n",
      "epoch  12| T | loss: 0.704 | score: 0.66 | V | loss: 0.697 | score: 0.621 | time: 0:00:37\n",
      "epoch  13| T | loss: 0.648 | score: 0.688 | V | loss: 0.698 | score: 0.635 | time: 0:00:36\n",
      "epoch  14| T | loss: 0.71 | score: 0.671 | V | loss: 0.68 | score: 0.646 | time: 0:00:37\n",
      "epoch  15| T | loss: 0.593 | score: 0.715 | V | loss: 0.709 | score: 0.642 | time: 0:00:36\n",
      "epoch  16| T | loss: 0.67 | score: 0.714 | V | loss: 0.691 | score: 0.679 | time: 0:00:36\n",
      "epoch  17| T | loss: 0.601 | score: 0.737 | V | loss: 0.662 | score: 0.68 | time: 0:00:37\n",
      "epoch  18| T | loss: 0.766 | score: 0.666 | V | loss: 0.671 | score: 0.695 | time: 0:00:37\n",
      "epoch  19| T | loss: 0.636 | score: 0.714 | V | loss: 0.653 | score: 0.656 | time: 0:00:37\n",
      "epoch  20| T | loss: 0.63 | score: 0.71 | V | loss: 0.687 | score: 0.668 | time: 0:00:36\n",
      "epoch  21| T | loss: 0.611 | score: 0.738 | V | loss: 0.627 | score: 0.703 | time: 0:00:37\n",
      "epoch  22| T | loss: 0.558 | score: 0.753 | V | loss: 0.643 | score: 0.696 | time: 0:00:36\n",
      "epoch  23| T | loss: 0.665 | score: 0.729 | V | loss: 0.619 | score: 0.703 | time: 0:00:35\n",
      "epoch  24| T | loss: 0.518 | score: 0.794 | V | loss: 0.645 | score: 0.686 | time: 0:00:37\n",
      "epoch  25| T | loss: 0.461 | score: 0.81 | V | loss: 0.609 | score: 0.711 | time: 0:00:36\n",
      "epoch  26| T | loss: 0.616 | score: 0.745 | V | loss: 0.622 | score: 0.686 | time: 0:00:35\n",
      "epoch  27| T | loss: 0.5 | score: 0.791 | V | loss: 0.604 | score: 0.725 | time: 0:00:36\n",
      "epoch  28| T | loss: 0.651 | score: 0.742 | V | loss: 0.622 | score: 0.685 | time: 0:00:35\n",
      "epoch  29| T | loss: 0.584 | score: 0.758 | V | loss: 0.58 | score: 0.704 | time: 0:00:36\n",
      "epoch  30| T | loss: 0.526 | score: 0.785 | V | loss: 0.612 | score: 0.713 | time: 0:00:36\n",
      "epoch  31| T | loss: 0.42 | score: 0.844 | V | loss: 0.622 | score: 0.714 | time: 0:00:36\n",
      "epoch  32| T | loss: 0.387 | score: 0.855 | V | loss: 0.618 | score: 0.727 | time: 0:00:36\n",
      "epoch  33| T | loss: 0.476 | score: 0.809 | V | loss: 0.626 | score: 0.702 | time: 0:00:36\n",
      "epoch  34| T | loss: 0.605 | score: 0.761 | V | loss: 0.63 | score: 0.7 | time: 0:00:35\n",
      "epoch  35| T | loss: 0.456 | score: 0.816 | V | loss: 0.611 | score: 0.709 | time: 0:00:37\n",
      "epoch  36| T | loss: 0.367 | score: 0.849 | V | loss: 0.65 | score: 0.713 | time: 0:00:37\n",
      "epoch  37| T | loss: 0.631 | score: 0.735 | V | loss: 0.592 | score: 0.717 | time: 0:00:36\n",
      "epoch  38| T | loss: 0.52 | score: 0.796 | V | loss: 0.591 | score: 0.706 | time: 0:00:36\n",
      "epoch  39| T | loss: 0.44 | score: 0.819 | V | loss: 0.568 | score: 0.724 | time: 0:00:35\n",
      "epoch  40| T | loss: 0.43 | score: 0.827 | V | loss: 0.58 | score: 0.741 | time: 0:00:36\n",
      "epoch  41| T | loss: 0.394 | score: 0.834 | V | loss: 0.595 | score: 0.725 | time: 0:00:37\n",
      "epoch  42| T | loss: 0.453 | score: 0.829 | V | loss: 0.607 | score: 0.728 | time: 0:00:36\n",
      "epoch  43| T | loss: 0.485 | score: 0.816 | V | loss: 0.612 | score: 0.732 | time: 0:00:37\n",
      "epoch  44| T | loss: 0.467 | score: 0.831 | V | loss: 0.602 | score: 0.728 | time: 0:00:37\n",
      "epoch  45| T | loss: 0.48 | score: 0.815 | V | loss: 0.584 | score: 0.727 | time: 0:00:35\n",
      "epoch  46| T | loss: 0.446 | score: 0.822 | V | loss: 0.586 | score: 0.72 | time: 0:00:35\n",
      "epoch  47| T | loss: 0.456 | score: 0.837 | V | loss: 0.579 | score: 0.736 | time: 0:00:36\n",
      "epoch  48| T | loss: 0.412 | score: 0.839 | V | loss: 0.581 | score: 0.723 | time: 0:00:36\n",
      "epoch  49| T | loss: 0.41 | score: 0.845 | V | loss: 0.566 | score: 0.73 | time: 0:00:37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/yuigahama/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- fold 1 ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/yuigahama/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-82fc5b32a01f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1498:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yuigahama/anaconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/yuigahama/anaconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yuigahama/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 216, in _worker_loop\n",
      "    pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "tta = np.zeros((len(submission), 24))\n",
    "cv_score = 0\n",
    "\n",
    "for fold_id, (train_index, val_index) in enumerate(skf.split(train_tp, train_tp.species_id)):\n",
    "    print(f'---------- fold {fold_id} ----------')\n",
    "    \n",
    "    model = BaseModel(**model_params).to(device)\n",
    "    optim = Adam(model.parameters(), **optim_params)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer=optim, **scheduler_params)\n",
    "    #scheduler = lr_scheduler.CosineAnnealingLR(optimizer=optim, T_max=epochs)\n",
    "    \n",
    "    pos_weights = torch.ones(25)\n",
    "    pos_weights = pos_weights * 25\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "    \n",
    "    train_dataset = RfcxDataSet(train_tp.iloc[train_index], **data_params)\n",
    "    val_dataset   = RfcxTestDataSet(train_tp.iloc[val_index], val=True, **data_params)\n",
    "    test_dataset  = RfcxTestDataSet(submission, **test_data_params)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, shuffle=True, **dataloder_params)\n",
    "    val_dataloader = DataLoader(val_dataset, shuffle=False, **dataloder_params)\n",
    "    test_dataloader = DataLoader(test_dataset, **test_dataloder_params)\n",
    "    \n",
    "    es = 15\n",
    "    for epoch in range(1, epochs):\n",
    "        if es == 0:\n",
    "            break\n",
    "        \n",
    "        start_time = time.time()\n",
    "        bast_score = 0\n",
    "        \n",
    "        # train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_score = 0\n",
    "        \n",
    "        for data in train_dataloader:\n",
    "            image = data[0].to(device)\n",
    "            label = data[1].to(device)\n",
    "            \n",
    "            pred, mix_info = model(image)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            \n",
    "            loss = mixup_socre(criterion, pred.cpu(), label.cpu(), mix_info)\n",
    "            score = mixup_socre(LWLRAP, torch.sigmoid(pred.cpu()), label.cpu(), mix_info)\n",
    "            #loss = criterion(pred, label)\n",
    "            #score = LWLRAP(pred.cpu(), label.cpu())\n",
    "            \n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_score += score\n",
    "            \n",
    "        train_loss  /= len(train_dataloader)\n",
    "        train_score /= len(train_dataloader)\n",
    "        \n",
    "        # val\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_score = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for val_data in val_dataloader:\n",
    "                num = len(val_data[0])\n",
    "                label = val_data[1]\n",
    "                tmp = torch.zeros((val_data[0][0].size(0), 25))\n",
    "                \n",
    "                for img in val_data[0]:\n",
    "                    pred, _ = model(img.to(device))\n",
    "                    tmp += pred.cpu() / num\n",
    "                \n",
    "                val_loss += criterion(tmp, label).item()\n",
    "                val_score += LWLRAP(torch.sigmoid(tmp), label)\n",
    "\n",
    "                \n",
    "        val_loss  /= len(val_dataloader)\n",
    "        val_score /= len(val_dataloader)\n",
    "        \n",
    "        duration = str(datetime.timedelta(seconds=time.time() - start_time))[:7]\n",
    "        print(f'epoch {epoch:3}| T | loss: {train_loss:.3} | score: {train_score:.3} | V | loss: {val_loss:.3} | score: {val_score:.3} | time: {duration}')\n",
    "\n",
    "        if bast_score < val_score:\n",
    "            bast_score = val_score\n",
    "            bast_path = save(fold_id, model, optim, criterion)\n",
    "        else:\n",
    "            es -= 1\n",
    "        \n",
    "        scheduler.step(val_score)\n",
    "            \n",
    "        \n",
    "    oof = np.zeros((len(test_dataset), 24))\n",
    "    model = BaseModel(**model_params).to(device)\n",
    "    \n",
    "    bast_model_parms = torch.load(bast_path)\n",
    "    model.load_state_dict(bast_model_parms['model_state_dict'])\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        start = 0\n",
    "        for i, test_data in enumerate(test_dataloader):\n",
    "            target_size = test_data[0].size(0)\n",
    "            tmp_pred = np.zeros((target_size, 24))\n",
    "            num = len(test_data)\n",
    "            end = start + target_size\n",
    "            for img in test_data:\n",
    "                img = img.to(device)\n",
    "                pred, _ = model(img)\n",
    "                \n",
    "                tmp_pred += torch.sigmoid(pred.cpu().detach()).numpy()[:, :-1] / num\n",
    "                       \n",
    "            oof[start:end, :] = tmp_pred\n",
    "            start = end\n",
    "            \n",
    "    tta += (oof / n_splits) \n",
    "    \n",
    "    del model, train_dataset, val_dataset, test_dataset, train_dataloader, val_dataloader, test_dataloader\n",
    "    del bast_model_parms, optim\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sub = pd.DataFrame(tta, columns=pred_target)\n",
    "pred_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([submission['recording_id'], pred_sub], axis=1).to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
